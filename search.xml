<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【论文笔记 7】Weighted Transfer Learning for MI</title>
    <url>/2020/04/08/Weighted-Transfer-Learning-for-MI/</url>
    <content><![CDATA[<center>Weighted Transfer Learning for Improving Motor Imagery-Based Brain–Computer Interface</center>  

<center>Ahmed M. Azab  et al.，谢菲尔德大学， 2019</center>

<center>IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING </center>

<p><strong>Abstract:</strong> 提出了一种基于模型参数的迁移学习方法。通过已有数据求得模型，将该模型参数迁移到含少量训练样本的target subject训练过程中，实现inter-subject 和 inter-session之间的迁移。针对已有数据和当前受试者之间可能存在的特征空间不一致等问题，在原迁移学习基础上增加了权重因子，实现对样本的筛选，这里相似度量方法采用KL散度。实验在3个公开数据集上进行了测试，分类模型采用逻辑回归。</p>
<p><strong>Note:</strong> 本文采用基于模型的迁移方法；提出了根据KL散度的样本筛选方法；逻辑回归。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Logistic-Regression-Based-Transfer-Learning-Algorithm-LTL"><a href="#Logistic-Regression-Based-Transfer-Learning-Algorithm-LTL" class="headerlink" title="Logistic Regression-Based Transfer Learning Algorithm (LTL)"></a>Logistic Regression-Based Transfer Learning Algorithm (LTL)</h2><p>本文采用逻辑回归作为分类器，迁移学习的实现分两步：第一步根据已有数据构造source domain的分类器模型；第二步在target domian模型训练过程中，正则项加入评估不同域模型参数相似性的因子。</p>
<h3 id="第一步-source-domain训练"><a href="#第一步-source-domain训练" class="headerlink" title="第一步 source domain训练"></a>第一步 source domain训练</h3><p>逻辑回归是一个基本的二分类模型，通过对线性模型进行变换，从而进行概率预测。模型预测值为一概率函数，对于二分类任务，通常认为0.5为分类阈值。该模型可以用logistic sigmoid函数表示为</p>
<img src="https://s1.ax1x.com/2020/04/08/GWJ4Z6.png" alt="logistic sigmoid" style="zoom:50%;" />

<p>该模型中，$S$表示某一个session，$X_s$表示样本特征矩阵，$W_s$为模型参数，即线性模型的权重。该模型的概率输出P根据分类阈值即可进行类别预测。该模型的关键是对参数$W_s$的估计，可以通过以下目标函数求得</p>
<img src="https://s1.ax1x.com/2020/04/08/GWtPAK.png" alt="GWtPAK.png" style="zoom:50%;" />

<img src="https://s1.ax1x.com/2020/04/08/GWtuHP.png" alt="GWtuHP.png" style="zoom:50%;" />

<p>(2)式中，H表示交叉熵，表示对训练误差的度量；正则项表示对$W_s$中较大值的惩罚，以减小过拟合。该目标函数求解在训练集上完成，同时我们知道<strong>回归模型无局部最优解</strong>，故该函数存在唯一的最小值，可以通过梯度下降或者牛顿法求解。</p>
<h3 id="第二步-target-domain训练"><a href="#第二步-target-domain训练" class="headerlink" title="第二步 target domain训练"></a>第二步 target domain训练</h3><p>对于new subject，模型的目标函数$L_1(w_S)$不仅要是分类错误率最低，还应让估计的模型参数$W_s$和source domain中尽量靠近，这样以实现模型参数的迁移，从而减少训练样本。</p>
<img src="https://s1.ax1x.com/2020/04/08/GWUT0I.png" alt="GWUT0I.png" style="zoom:50%;" />

<p>其中$R_{TL}$表示对$W_t$和$W_s$的相似性惩罚</p>
<img src="https://s1.ax1x.com/2020/04/08/GWaVc4.png" alt="GWaVc4.png" style="zoom:50%;" />

<p><font color=red>这里需要注意的是：$μ$和$\sum_{TL}$均是对source domain数据分布的估计，且该迁移过程是按照session/subject来的。</font></p>
<h2 id="Weighted-Logistic-Regression-Based-Transfer-Learning-Algorithm"><a href="#Weighted-Logistic-Regression-Based-Transfer-Learning-Algorithm" class="headerlink" title="Weighted Logistic Regression-Based Transfer Learning Algorithm"></a>Weighted Logistic Regression-Based Transfer Learning Algorithm</h2><p><strong>把每个session进行同样权重的迁移是可行的吗？实际上由于EEG信号的非平稳性，EEG信号经过CSP后会进入不同的特征空间。</strong><font color=shocking pink>什么情况下需要调整权重？首先我们需要衡量数据的空间分布是否一致。</font></p>
<p>本文作者通过计算source domian session和target domain session之间的KL散度，评估session之间的相似性，从而调整迁移过程中的$W_s$系数。首先，通常认为数据经过CSP后特征呈现正态分布，那么对于两正态分布的数据集$N_0(μ_0, \sum_0)$和$N_1(μ_1, \sum_1)$，KL散度为</p>
<img src="https://s1.ax1x.com/2020/04/08/GWrbrD.png" alt="GWrbrD.png" style="zoom:50%;" />

<p>这里的KL散度计算有监督和无监督两种方式。<strong>监督(S-wLTL)</strong>: session中按照类别不同分别计算KL散度，最后取平均；<strong>无监督(Us-wLTL)</strong>: session直接计算。最后得加权系数为</p>
<img src="https://s1.ax1x.com/2020/04/08/GWy9YR.png" alt="GWy9YR.png" style="zoom:50%;" />

<p>$R_{TL}$中参数更新为</p>
<img src="https://s1.ax1x.com/2020/04/08/GW6l59.png" alt="GW6l59.png" style="zoom:50%;" />

<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p><img src="https://s1.ax1x.com/2020/04/08/GWcaQ0.png" alt="Results"></p>
<p>可以看到，在三个数据集上，当受试者trial数较少时，迁移学习方法能够达到显著的效果。随着trial数增加，迁移学习的效果不再明显。<strong>值得注意的是，对于dataset 3，trial数增加的时候迁移学习效果不如SS（SVM）方法效果。这可能是因为当前数据集只包含5个受试者的原因。</strong></p>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><ul>
<li>KL散度计算时需要极端协方差矩阵，当受试者trial数不足时，该协方差矩阵并不能真实反映数据分布情况，可以尝试对协方差矩阵进行更有效的估计或者采用其他的度量方法；</li>
<li>我们根据KL散度计算加权系数时，power值为4，改超参数未进行优化；</li>
<li>本文的方法并不局限与逻辑回归的应用。</li>
</ul>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>MI</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【神经工程学】第三章 神经检测与成像</title>
    <url>/2020/04/07/%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%88%90%E5%83%8F/</url>
    <content><![CDATA[<p>第三章 神经检测与成像</p>
<ul>
<li>3.1 神经系统电信号及检测</li>
<li>3.2 CT成像原理及应用</li>
<li>3.3 磁共振成像(MRI)</li>
<li>3.4 磁共振技术的发展及应用趋势</li>
<li>3.5 光学成像的原理和应用</li>
<li>3.6 MEG信号的检测及应用</li>
</ul>
<a id="more"></a>

<h2 id="3-1-神经系统电信号及检测"><a href="#3-1-神经系统电信号及检测" class="headerlink" title="3.1 神经系统电信号及检测"></a>3.1 神经系统电信号及检测</h2><ul>
<li>EEG发展历史；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GckXi4.png" alt="EEG发展"></p>
<ul>
<li>国际10-20系统；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcADkF.png" alt="10-20"></p>
<ul>
<li>EEG信号频段；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcAIte.png" alt="频率成分"></p>
<h2 id="CT成像原理及应用"><a href="#CT成像原理及应用" class="headerlink" title="CT成像原理及应用"></a>CT成像原理及应用</h2><ul>
<li>1895年，德国物理学家伦琴发现并命名X射线；</li>
<li>计算机断层扫描成像(Computed Tomography, CT);</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcEXvR.png" alt="CT"></p>
<ul>
<li>CT成像由数据采集和图像重建构成； </li>
<li>增强CT：人为添加造影剂，使成像后的病灶更加清晰；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GceyE6.png" alt="增强CT"></p>
<ul>
<li>CT灌注成像；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/Gcefvd.png" alt="灌注成像"></p>
<h2 id="3-3-磁共振成像-MRI"><a href="#3-3-磁共振成像-MRI" class="headerlink" title="3.3 磁共振成像(MRI)"></a>3.3 磁共振成像(MRI)</h2><ul>
<li>MRI的分类；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcnQwq.png" alt="MRI"></p>
<h2 id="3-4-磁共振技术的发展及应用趋势"><a href="#3-4-磁共振技术的发展及应用趋势" class="headerlink" title="3.4 磁共振技术的发展及应用趋势"></a>3.4 磁共振技术的发展及应用趋势</h2><ul>
<li>MRI设备发展趋势：更高的外加磁场强度，场强越大则图像信噪比越高；更快的成像速度(目前为百ms级)；研究新型结构成像方式；</li>
<li>脑连接组(Connectome)学研究；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcMxAI.png" alt="脑连接组"></p>
<p><img src="https://s1.ax1x.com/2020/04/07/GcQuCV.png" alt="研究方向"></p>
<h2 id="3-5-光学成像的原理和应用"><a href="#3-5-光学成像的原理和应用" class="headerlink" title="3.5 光学成像的原理和应用"></a>3.5 光学成像的原理和应用</h2><ul>
<li>光学成像的两个重要参数：数值孔径和分辨率；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/Gc3ORP.png" alt="参数"></p>
<ul>
<li>光学成像方法：荧光成像方法；生物发光学成像方法；光声成像方法；相干断层成像方法；功能性近红外光谱方法；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcJIqU.png" alt="应用展望"></p>
<h2 id="3-6-MEG信号的检测及应用"><a href="#3-6-MEG信号的检测及应用" class="headerlink" title="3.6 MEG信号的检测及应用"></a>3.6 MEG信号的检测及应用</h2><ul>
<li>MEG发展历史。1968年， David Cohen使用铜感应线圈作为检测器， 首次测量到了颅内电流变化产生的磁场及MEG信号， 但信号很差， 信噪比极低；  </li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcYRTe.png" alt="发展历史"></p>
<ul>
<li>MEG信号特点：瞬时性、动态性、非平稳性、具有空间位置差异性、受介质（颅骨、头皮等）影响较小、极微弱，百fT(1fT=$10^{-15}$Tesla)量级；</li>
<li>MEG的观察指标有极性、振幅、频率、潜伏期、能量和相关性等；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcUCoF.png" alt="观察指标"></p>
<ul>
<li>相关技术对比；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/07/GcUJyt.png" alt="对比"></p>
]]></content>
      <categories>
        <category>神经工程学</category>
      </categories>
      <tags>
        <tag>公开课笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>【神经工程学】第二章 神经生理心理基础 part2</title>
    <url>/2020/04/06/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%94%9F%E7%90%86%E5%BF%83%E7%90%86%E5%9F%BA%E7%A1%80-part2/</url>
    <content><![CDATA[<p>第二章 神经生理心理基础</p>
<ul>
<li>2.4 神经元电生理特性</li>
<li>2.5 突触与突触传递</li>
<li>2.6 神经心理学概述</li>
<li>2.7 心理学过程的神经学机制</li>
</ul>
<a id="more"></a>

<h2 id="2-4-神经元电生理特性"><a href="#2-4-神经元电生理特性" class="headerlink" title="2.4 神经元电生理特性"></a>2.4 神经元电生理特性</h2><ul>
<li>1820年，德国科学家测得在肌肉完好和损伤部位之间存在电位差。即损伤电位，为负值；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyKNqI.png" alt="损伤电位"></p>
<ul>
<li>细胞在生命活动时伴随着电现象，是由带电离子跨膜运输产生的，表现为跨膜电位(Transmembrane Potential)或膜电位(Membrane Potential)；</li>
<li><strong>静息电位(Resting Potential):</strong> 细胞在安静时存在于膜两侧的电位差。内负外正，为一稳定的直流电位，不同细胞静息电位不同，范围在-10~-100mV之间；</li>
<li>静息电位产生的前提1：细胞膜内外存在离子浓度差。离子所受的驱动力为<strong>电化学驱动力</strong>；</li>
<li>静息电位产生的前提2：细胞膜对离子的通透性不同。<strong>平衡电位(Equilibrium Potential)</strong>指某种离子所受电化学驱动力为0，不在做跨膜移动时的膜电位值。细胞的静息电位接近于$K^+$的平衡电位；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/Gy8PaR.png" alt="离子浓度差"></p>
<p><img src="https://s1.ax1x.com/2020/04/06/Gy8cyF.png" alt="离子通透性"></p>
<ul>
<li>细胞膜在静息状态下对$K^+$通透性远高于$Na^+$ (100:1)，细胞膜上钠钾泵的存在维持着静息态膜内外$K^+$浓度不平衡；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyG7hq.png" alt="静息电位"></p>
<ul>
<li><strong>动作电位(Action Potential):</strong> 可兴奋细胞受到有效刺激后产生的一过性的电位活动。其特点是瞬时、可逆、传导性（可扩步）；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyYAGq.png" alt="动作电位组成"></p>
<ul>
<li>动作电位的钠学说；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/Gyt5He.png" alt="钠学说"></p>
<ul>
<li>AP机制；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyNzM6.png" alt="AP机制"></p>
<ul>
<li>阈电位；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GygJSO.png" alt="阈电位"></p>
<ul>
<li>动作电位的触发；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/Gyg4kq.png" alt="阈电位的产生机制"></p>
<ul>
<li>动作电位的特点；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyR1xO.png" alt="特点"></p>
<ul>
<li>膜的被动电学特性以及电紧张电位(electrotonic potential)；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyRxSK.png" alt="被动电学模型"></p>
<p><img src="https://s1.ax1x.com/2020/04/06/GyWiTA.png" alt="电紧张电位"></p>
<ul>
<li>局部电位(Local Potential)，不存在“全或无”现象，呈电紧张形式扩步；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyWDt1.png" alt="LP"></p>
<ul>
<li>动作电位和局部电位对比；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyfvrD.png" alt="AP VS. LP"></p>
<h2 id="2-5-突触与突触传递"><a href="#2-5-突触与突触传递" class="headerlink" title="2.5 突触与突触传递"></a>2.5 突触与突触传递</h2><ul>
<li>突触的定义；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyhhWt.png" alt="突触"></p>
<ul>
<li>突触分电突触和化学突触(Chemical synapse)两种。化学突触即我们熟知的以神经递质作为传递媒介的突触，在高等哺乳动物大脑中几乎都是化学突触；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/Gy4Y1P.png" alt="电突触"></p>
<p><img src="https://s1.ax1x.com/2020/04/06/Gy5kDS.png" alt="化学性突触"></p>
<ul>
<li>神经递质的去向；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyoZpn.png" alt="神经递质去向"></p>
<h2 id="2-6-神经心理学概述"><a href="#2-6-神经心理学概述" class="headerlink" title="2.6 神经心理学概述"></a>2.6 神经心理学概述</h2><ul>
<li>定义：将大脑视为心理活动的物质本体，综合研究二者关系；</li>
<li>发展历史；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/GyTpC9.png" alt="发展历史"></p>
<ul>
<li>神经心理学三大分支：临床、实验和认知神经心理学。其中认知神经心理学：从信息加工的角度来了解与具体认知心理活动相关的大脑结构和功能，采集神经心理测试过程中的大量脑活动相关数据，以信息加工角度挖掘潜在神经机制；</li>
</ul>
<h2 id="2-7-心理学过程的神经学机制"><a href="#2-7-心理学过程的神经学机制" class="headerlink" title="2.7 心理学过程的神经学机制"></a>2.7 心理学过程的神经学机制</h2><ul>
<li>现代大脑功能理论模型</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/04/06/Gy7QJJ.png" alt="Model"></p>
]]></content>
      <categories>
        <category>神经工程学</category>
      </categories>
      <tags>
        <tag>公开课笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记 6】Euclidean space data alignment</title>
    <url>/2020/04/04/Euclidean-space-data-alignment/</url>
    <content><![CDATA[<center>Transfer Learning for Brain–Computer Interfaces:
    A Euclidean Space Data Alignment Approach</center> 
<center>He He et al., 华中科技大学，2020</center>

<center>IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING </center>

<p><strong>Abstract:</strong> 提出了一种欧式空间下的数据对齐方法，通过对不同受试者的EEG trial进行数据对齐，增加inter-subject之间的数据相似性，从而达到迁移学习的目的。作者将提出的方法EA与黎曼空间下的数据对齐方式RA进行了对比，离线和在线测试均表明了其优越性。实验测试数据分MI和ERP两类，分类器采用最小黎曼均值距离MDRM、LDA和SVM。</p>
<p><strong>Note:</strong> EA可以看成一种子空间学习的方法，通过将源域和目标域同时变换增加相似性；论文中包含了较多黎曼流行学习的文献；介绍了一种增加ERP协方差矩阵时域信息的方法；受试者空闲态数据对迁移学习有帮助(RA-MDRM)。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Manifold-learning"><a href="#Manifold-learning" class="headerlink" title="Manifold learning"></a>Manifold learning</h2><h3 id="Riemannian-Distance"><a href="#Riemannian-Distance" class="headerlink" title="Riemannian Distance"></a>Riemannian Distance</h3><p>EEG trial 之间的协方差矩阵是对称正定(SPD)的，故该矩阵在黎曼空间内，可以表示为流形上的一个点<font color=red>（关于流形学习的论文可以参考F. Lotte：Riemannian approaches in brain-computer interfaces: A review）</font>。两个SPD矩阵之前的黎曼距离以流形上的测地线geodesic长度衡量</p>
<p><img src="https://s1.ax1x.com/2020/04/04/G0MrKP.png" alt="RD"></p>
<p>对两个SPD矩阵进行可逆线性变换，不改变两者在流形上的黎曼距离，这个性质被称为同余不变性(congruence invariance)。</p>
<h3 id="MDRM"><a href="#MDRM" class="headerlink" title="MDRM"></a>MDRM</h3><p>首先，黎曼空间上的黎曼均值距离定义为使黎曼距离平方的均值最小化的矩阵P，该矩阵可以通过梯度下降求解。</p>
<p><img src="https://s1.ax1x.com/2020/04/04/G0QddU.png" alt="RM"></p>
<p>MDRM分类器的思想类似于欧式空间下的欧氏距离分类，通过计算测试数据的协方差矩阵，然后度量其与各个类别黎曼均值之间的黎曼距离，距离最小者属于该类别</p>
<p><img src="https://s1.ax1x.com/2020/04/04/G0lPO0.png" alt="MDRM"></p>
<h3 id="RA-MDRM"><a href="#RA-MDRM" class="headerlink" title="RA-MDRM"></a>RA-MDRM</h3><p>Zanini et al.  2018年提出了一种黎曼空间下的迁移学习方法，即RA-MDRM，利用其他session和subject的数据来增强当前受试者的分类效果。作者对来自不同session和subject的协方差矩阵根据一个共同参考进行align。论文认为当大脑在执行一个特定的任务时，流形上的协方差矩阵会向同一个方向移动，则可以将协方差矩阵按参考方向进行聚集，那我们只需要观察距离参考态的相对位移即可。所以该方法的关键是找到该reference matrix，该矩阵通过受试者的空闲态求得<strong>（MI为受试者不进行运动想象时的数据，ERP中即受试者未受外界刺激non-target stimuli时的数据，故ERP中需要知道标签信息，才能确定非目标刺激）</strong>，利用空闲态数据矩阵可求得黎曼均值$\bar{R}$。然后利用该参考矩阵对当前数据进行变换，即可减少inter-session/subject variability </p>
<p><img src="https://s1.ax1x.com/2020/04/04/G08D76.png" alt="reference"></p>
<h3 id="关于协方差矩阵"><a href="#关于协方差矩阵" class="headerlink" title="关于协方差矩阵"></a>关于协方差矩阵</h3><p>在运动想象中，trial$X_i$的协方差矩阵可以通过$\sum_i=X_iX^T_i$求得，但是该矩阵只能反映大脑活动的空间分布，这对MI任务是适合的。但是针对ERP范式，其最优分类信息在时域上，所以需要对该协方差矩阵计算进行修改，增加时域信息。<font color=shocking pink>这里开一个脑洞：目前识别SSVEP均是利用了其时域信息进行相关性计算，类似于CSP等空域滤波方法效果不好是不是因为该协方差矩阵没有进行改进呢？我们是否可以按这里的方法有效ERP信号的时域和空域信息，从而达到很好的效果呢？</font></p>
<p><img src="https://s1.ax1x.com/2020/04/04/G0YnpD.png" alt="ERP 协方差计算"></p>
<h2 id="EEG-data-alignment-in-the-Euclidean-Space-EA"><a href="#EEG-data-alignment-in-the-Euclidean-Space-EA" class="headerlink" title="EEG data alignment in the Euclidean Space (EA)"></a>EEG data alignment in the Euclidean Space (EA)</h2><h3 id="The-EA"><a href="#The-EA" class="headerlink" title="The EA"></a>The EA</h3><p>通过使不同受试者的数据分布相似化，从而一个数据集中训练好的分类器在其他受试者上亦会有较好的分类效果，这是TL的基本思想。和RA一样，EA也需要构造参考矩阵$\bar{R}$，该矩阵通过计算所有数据的的协方差算术平均而得。<font color=shocking pink>论文中说参考矩阵是由受试者所有trial计算而来，意思是包括所有类别的数据一起？这和【论文笔记 5】中采用的cross-subject不同，该作者是按照类别进行迁移的。</font></p>
<p><img src="https://s1.ax1x.com/2020/04/04/G0asr4.png" alt="EA"></p>
<h3 id="Comparison-with-RA"><a href="#Comparison-with-RA" class="headerlink" title="Comparison with RA"></a>Comparison with RA</h3><ul>
<li>EA和RA在进行数据对齐后，其协方差矩阵的黎曼距离并不会改变（同余不变性）；</li>
<li>RA的参考矩阵来自于受试者空闲态的黎曼均值，而EA是在欧式空间计算所有trial的协方差矩阵；</li>
<li>RA在黎曼空间进行数据对齐，而EA在欧式空间；</li>
<li>EA的计算简单，速度快；</li>
<li>EA不需要新的受试者带标签的数据，而RA应用在ERP范式中时，需要受试者的标签信息，从而构造空闲态参考矩阵。</li>
</ul>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><h2 id="Data-visualization"><a href="#Data-visualization" class="headerlink" title="Data visualization"></a>Data visualization</h2><p><img src="https://s1.ax1x.com/2020/04/04/G0wN90.png" alt="EA results 1"></p>
<p>上述为来自Dataset 2a的受试者1左右手想象数据，纵轴表示导联，数值表示经过EA前后的数据相关系数大小。可以发现，经过EA操作后，数据幅值明显降低，并且相关性减小。</p>
<p><img src="https://s1.ax1x.com/2020/04/04/G00dPI.png" alt="EA results 2"></p>
<p>作者通过t-Stochastic Neighbor Embedding (t-SNE) 算法，将来自MI和ERP范式的受试者测试数据（红色点）和训练数据（蓝色点）进行特征可视化，左右图分别为EA前后的效果。可以发现EA可以使训练和测试数据分布变得统一（除个别情况，后面会讨论）。</p>
<h2 id="Offline-unsupervised-classification"><a href="#Offline-unsupervised-classification" class="headerlink" title="Offline unsupervised classification"></a>Offline unsupervised classification</h2><p>对数据集进行leave-one-subject-out cross-validation，每次选择一个受试者当test set，其余受试者为training set。算法大概流程为：<strong>利用所有受试者（包括测试受试者）的数据求参考矩阵$\bar{R}$；</strong>再对数据进行align操作，使不同受试者之间的数据相似性增加；利用其它受试者的数据训练分类器，并在当前受试者上进行测试。<font color=red>为什么说这里是无监督学习呢？这是针对当前受试者而言，我们并没有利用来自他的标签信息，我们的SVM等分类器模型是根据其他受试者训练而得。</font><font color=shocking pink>这里我们利用了所有受试者的数据计算参考矩阵，包括test set。<strong>这里我们并不知道test set的标签，意味着EA在计算参考矩阵的时候，是没有将类别分开的。</strong>而在实际的应用中，test 按trial慢慢送入，故参考矩阵没办法利用当前受试者信息，除非当前受试者已有部分数据，类似于文章后面讨论的在线监督模型。</font></p>
<h3 id="MI-Datasets"><a href="#MI-Datasets" class="headerlink" title="MI Datasets"></a>MI Datasets</h3><p><img src="https://s1.ax1x.com/2020/04/04/G0DGAH.png" alt="MI"></p>
<p>首先可以看到，不管是RA还是EA，应用过后均取得了较好的效果；EA-CSP-LDA的效果最佳。</p>
<h3 id="ERP-Dataset"><a href="#ERP-Dataset" class="headerlink" title="ERP Dataset"></a>ERP Dataset</h3><p><img src="https://s1.ax1x.com/2020/04/04/G0DgCn.png" alt="ERP"></p>
<h3 id="参考矩阵的取法？"><a href="#参考矩阵的取法？" class="headerlink" title="参考矩阵的取法？"></a>参考矩阵的取法？</h3><p>由前面算法的推导可以看出，参考矩阵对迁移效果影响很关键，然而本文有四种参考矩阵的求法：Riemannian mean of the resting trials (RR), Euclidean mean of the resting trials (ER), Riemannian mean of all imagery trials (RI), and Euclidean mean of all imagery trials (EI) . 采用不同的参考，在MI数据集上进行测试后可以发现，<strong>还是EI（即EA）最佳。</strong></p>
<p><img src="https://s1.ax1x.com/2020/04/04/G0s4k4.png" alt="G0s4k4.png"></p>
<h2 id="Simulated-online-supervised-classification"><a href="#Simulated-online-supervised-classification" class="headerlink" title="Simulated online supervised classification"></a>Simulated online supervised classification</h2><p>本文亦进行了在线监督学习，即选取一个受试者的数据，将其中一部分保留作为测试数据，其余部分为在线添加的带标签样本。随着实验的进行，不断的添加标记样本进去，从而更新参考信号，分类器的训练也用到了新添加的标记样本。<font color=red>（这里进行在线监督分类的目的应该是为了验证当前受试者已有样本数对分类效果的影响）。</font><strong>篇幅有限，不具体讨论了，EA的效果较优。</strong></p>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><p>首先，不同受试者之间存在的数据漂移包括三类：<strong>Covariate shift, Prior probability shift, Concept shift</strong>.</p>
<ul>
<li>EA仅考虑了covariate shift;</li>
<li>EA有可能会增加concept shift，即经过EA操作后，类别之间变得更加难分；</li>
<li>已有的数据中可能会存在一些bad trials/outliers等，若将其纳入参考信号的求取，会影响正确率。</li>
</ul>
<h1 id="感触"><a href="#感触" class="headerlink" title="感触"></a>感触</h1><p>论文中也说了，如果对已有数据不进行筛选的话，是会影响最终结果的，所以可以考虑利用一些度量标准进行数据筛选（模糊C均值？）；EA虽然应用到了ERP上，但本文讨论的只是RSVP 5Hz下二分类的结果，对SSVEP有效吗？</p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>MI</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>关于我的博客</title>
    <url>/2020/04/02/%E5%85%B3%E4%BA%8E%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<center>欢迎来到我的吐槽空间</center>

<blockquote>
<p>突然有一天想搭一个博客记录生活中的一些琐事，看了很多教程后便着手做了这件事。作为一个前端业余爱好者，所以也没什么经验值得分享，博客是利用hexo+github/gitee搭建的，感谢原作者贡献的主题<a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank" rel="noopener">Ayer</a>。后续会逐渐添加更多的功能。</p>
</blockquote>
<p><img src="https://s1.ax1x.com/2020/04/02/GYPzvV.png" alt="ONE PIECE"></p>
<a id="more"></a>

<h2 id="这里面记录了什么呢？"><a href="#这里面记录了什么呢？" class="headerlink" title="这里面记录了什么呢？"></a>这里面记录了什么呢？</h2><h3 id="大多数是论文笔记"><a href="#大多数是论文笔记" class="headerlink" title="大多数是论文笔记"></a>大多数是论文笔记</h3><p><strong>毕竟看论文才是研究生的日常。</strong>以前喜欢论文打印出来阅读，笔记心得什么的都写在上面，后来发现离开实验室太不方便了，特别是这次疫情深有体会。本人是做脑-机接口(Brain-Computer Interface, BCI)的水硕一名，主要研究方向是稳态视觉诱发电位(Steady-State Visual Evoked Potential, SSVEP)识别<font color=red>（真不想说自己是做研究的…我这垃圾水平别玷污了研究这个神圣的词）</font>。所以呢，论文笔记关于BCI/SSVEP的多一些。当然，还会更新一些信号处理、机器学习的内容。我觉得用博客做论文笔记真是一件很必要的事，能够转述别人的论文成果，能够总结其中的要点，能够开一些脑洞……对自己的提升都会有很大帮助。毕竟，不能脱口而出乃至授人以渔的知识，都不是自己已经掌握的知识。这里的笔记记录主要是方便自己思考和回顾，如果想看高质量的人工智能论文解读和推荐，转<a href="http://www.paperweekly.site/" target="_blank" rel="noopener">Paperweekly</a>。</p>
<h3 id="部分为一些杂记"><a href="#部分为一些杂记" class="headerlink" title="部分为一些杂记"></a>部分为一些杂记</h3><p>包括一些心灵鸡汤和随笔。</p>
<p><strong>学习真是一件很神奇的事，你会越来越发现自己有多无知又有多值得努力。</strong>我爱我的母校西大，但是我却遗憾自己在那里没能接受到前沿的教育，这可能是大多数高校存在的问题。本科的时候是在电子科创实验室，主要做一些控制方面的东西，也得过一些全国的奖，什么电赛、全国机器人大赛之类的。后来参加的比赛多了，见识过其他学校的同学水平，那时候才意识到自己眼界和能力有多欠缺。那种感觉就好像是你在使用旧式步枪，而对方已经开始应用自动制导了一样。虽然你正中十环，但对方给你的震慑力远比这微不足道的成绩更值得留意。那时候我开始对AI这个行业抱有强烈的兴趣，后来看过一些零星的报道和书籍，这里推荐微软亚洲研究院院长洪小文2017年在清华的报告：<a href="https://www.msra.cn/zh-cn/news/features/hon-the-brief-history-of-intelligence-1" target="_blank" rel="noopener">以科学的方式赤裸裸地剖析人工智能</a>。</p>
<p><strong>保持好奇心和激情是一件很难却很酷的事。</strong>我记得推免的时候系主任问我以后的规划，我说我想学智能算法让自己做的机器人有灵魂，哈哈哈，现在想想这种话也好意思在这么多老师面前说出口。后来来到了CQU，套用实验室师兄毕业论文中的致谢以表达我对导师们的感激之情：先生不以余学术浅陋，将余纳入门墙，从此言传身教，亲生相授。学生不敏，未习得先生一二，然耳濡目染，亦有所获。虽然自己很菜，但所幸对现在的研究方向颇为感兴趣，希望勤勤恳恳有所获。BCI以后肯定会很火，毕竟我的偶像Elon Musk也在17年创办了Neruolink。</p>
<h3 id="还有一些关于爱好"><a href="#还有一些关于爱好" class="headerlink" title="还有一些关于爱好"></a>还有一些关于爱好</h3><p>以后会在博客中开专栏更摄影的东西。</p>
<p><strong>一定要开始学剪辑了。</strong>感觉没点爱好生活好像失去了一些灵魂要素。都在B站观望摄影好多年了，迟迟不开始主要是因为穷……等着今年一定要把α6400或者M6 mark II买了。会旅拍真是一件很酷的技能，无论是转场、运镜还是剪辑，早点熟练就可以早点记录下一些精彩的故事。</p>
<p>&nbsp; &nbsp;</p>
<p>“人的梦想是不会终止的”</p>
<p>对喜欢的事多一点偏执和理想主义挺好</p>
<p>以上，是关于我的博客的介绍，亦是来自内心纠结的自述</p>
]]></content>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记 5】Cross-Subject Transfer Learning based SSVEP</title>
    <url>/2020/04/01/Cross-Subject-Transfer-Learning-based-SSVEP/</url>
    <content><![CDATA[<center>Cross-Subject Transfer Learning Improves the Practicality of
    Real-World Applications of Brain-Computer Interfaces</center>

<center>Kuan-Jung Chiang, 加州大学圣迭戈分校, 2019</center>

<center>9th International IEEE EMBS Conference on Neural Engineering</center>

<p><strong>Abstract:</strong> 通过其他受试者的数据对现有测试者template进行增广，并利用TRCA验证增广前后的分类性能。其中，作者利用最小二乘变换(Least-Squares Transformation, LST)  将其他人的数据变换为当前受试者的template，从而增加训练集。实验测试了template增广前后以及LST使用前后的效果，实验表明，当受试者template trial数较少（即训练集数量较小）时，LST具有明显的优势。</p>
<p><strong>Note:</strong>  利用现有数据实现受试者之间的template迁移，本文是通过LST将其他受试者数据变换到当前受试者的数据空间上<font color=red>（类似于增大其他人数据与当前受试者之间的相似度）</font>;内含部分SSVEP中迁移学习的文献。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Least-Squares-Transformation-LST"><a href="#Least-Squares-Transformation-LST" class="headerlink" title="Least-Squares Transformation (LST)"></a>Least-Squares Transformation (LST)</h2><p>本文的整体出发点是认为受试者之间的SSVEP信号存在变换关系，即可以通过变换矩阵P将已有受试者数据$\acute{x}$变换为与当前受试者$x$一致，即$x=P\acute{x}$。其中变换矩阵P可以通过channel-wise最小二乘回归求得，见图</p>
<p><img src="https://s1.ax1x.com/2020/04/01/G16zrt.png" alt="LST"></p>
<p>在实际应用过程中，当前受试者的数据$\bar{x}$根据训练集数量进行trial平均,将existing subjects的$N_t$个trial数据按通道进行LST计算，最后得到变换后的$N_t$个trial数据$\acute{x}_{trans}$。</p>
<h2 id="Three-schemes-for-SSVEP-decoding"><a href="#Three-schemes-for-SSVEP-decoding" class="headerlink" title="Three schemes for SSVEP decoding"></a>Three schemes for SSVEP decoding</h2><p>本文对比了subjects迁移前后，使用LST计算template前后的分类效果，三种scheme：Baseline、w/o LST和w/LST如下图</p>
<p><img src="https://s1.ax1x.com/2020/04/01/G1gl0P.png" alt="schemes"></p>
<p>实验数据分为8 subjects * 2 sessions * 15 blocks * 40 targets，故对每个session包含15个trial per stimulus，上图亦是针对每个session而言，将15个trial划分成5个训练（生成template）和10个测试，并重复了10次随机划分。8个受试者之间执行了LOO。<font color=shocking pink>值得留意的是，这里论文并没有告诉来自其他受试者的trial数量有多少问题。实际上，来自其他受试者的trial数应该是会对结果产生影响的，毕竟没有进行数据筛选。</font></p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p><img src="https://s1.ax1x.com/2020/04/01/G12Fjs.png" alt="结果"></p>
<p><img src="https://s1.ax1x.com/2020/04/01/G12aCD.png" alt="结果"></p>
<p>从图中可以看到</p>
<ul>
<li><font color=red>当template size较小时，通过其他受试者数据的引入，能够提高分类正确率；</font></li>
<li>随着template size的增加（到5时，即每个刺激包含5个训练样本），w/LST方法与Baseline方法无显著差异；</li>
<li>w/LST方法具有显著优势，特别是当受试者的训练数据不足时。</li>
</ul>
<h1 id="感触"><a href="#感触" class="headerlink" title="感触"></a>感触</h1><p>当前SSVEP的频率识别多是根据相关性的方法，其中的关键问题是template的获取，故本文研究的迁移学习思想也是针对template的改进，将已有数据向测试受试者的数据进行逼近。<font color=shocking pink><strong>是否存在更好的特征迁移方法？比如将其他受试者的数据和当前受试者的数据变换到相同的数据空间。（本文是通过特征变换方式减少源域和目标域的差异，采用统一变换到相同特征空间呢？）</strong></font></p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
        <tag>SSVEP</tag>
      </tags>
  </entry>
  <entry>
    <title>云</title>
    <url>/2020/03/31/%E4%BA%91/</url>
    <content><![CDATA[<p>在门前拍到看着很舒服的云。</p>
<p><img src="https://s1.ax1x.com/2020/03/31/GMvG60.png" alt="云"></p>
<a id="more"></a>

<p>突然感觉到了力不从心，无论是对学习的规划，还是对自己爱好的培养，都没能得到满足和平衡。上午看了中科院王晋东博士对迁移学习的总结，里面有句引用写得真好：<strong>吾生也有涯，而知也无涯。以有涯随无涯，殆已。</strong>可能自己需要多一些理性的思考，对自己努力的方向有更清晰的认识……</p>
]]></content>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>【ML】Introduction</title>
    <url>/2020/03/31/Introduction/</url>
    <content><![CDATA[<blockquote>
<p>课程简介：本课程是国立台湾大学<a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html" target="_blank" rel="noopener">李宏毅(Hung-yi Lee)老师</a>2020年春期课程，课程内容包含回归、分类、深度学习、迁移学习、强化学习、元学习等重要内容。<img src="https://s1.ax1x.com/2020/03/31/GK1wfs.png" alt="知识图谱"></p>
</blockquote>
<p><strong>Note:</strong> 作为非计算机科班出生的理工科学生，能够找到一个适合自己学习的机器学习课程并不容易。以前常自己啃西瓜书，后来发现没有系统的接受课程训练，对ML的理解并不深入。此外，李老师的台湾腔以及幽默的授课风格真让人爱了。本文及后续博文是关于本课程的学习笔记，其中<font color=shocking pink >绿色部分</font>是自己不成熟的思考。</p>
<a id="more"></a>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>机器学习的任务就是找出输入与输出之前的函数关系，其内容不仅包含回归和分类，还包括generation（GAN, seq2seq等）；</li>
<li>最新的Alpha zero应用的是强化学习；</li>
<li>函数的寻找方法——梯度下降；</li>
</ul>
<p><strong>下面是一些前沿研究课题</strong></p>
<ul>
<li>Explainable AI: 我们需要对机器为什么做出一个决策做分析；</li>
<li>Adversarial Attack: 我们所设计的模型都具有一定的鲁棒性，即在噪声的干扰下能够保持较好的性能。但是如果我们加入的噪声是经过一定修饰的，那我们的机器会做出什么样的决策呢？</li>
<li>Network Compression: 如果我们设计的模型很大，那如何把它嵌入到类似手机一样的小设备中？</li>
<li>Anomaly Detection: 如果把做好的模型用到线上，输入样本中出现了训练阶段从来未遇到过的样本类型（比如做动物识别，但是放入了汽车的照片），那机器怎么知道它不知道这个样本是什么的哲学问题；</li>
<li>迁移学习（这里推荐中科院博士整理的<a href="http://transferlearning.xyz/#0latest-publications-%e6%9c%80%e6%96%b0%e8%ae%ba%e6%96%87" target="_blank" rel="noopener">超全的资料</a>）；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/31/GK0aA1.png" alt="迁移学习"></p>
<ul>
<li><font color=red>Meta Learning:</font> 学习如何学习，赋予机器学习如何学习的能力。机器学习是写一段程序让机器具有学习能力，而元学习是写一段程序，这个程序可以用来写另外一段程序，使之具有学习功能；</li>
<li>Life-long Learning: 让机器不断地学习，使之能够处理的任务不断增加；</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>公开课学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【神经工程学】第二章 神经生理心理基础 part1</title>
    <url>/2020/03/30/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%94%9F%E7%90%86%E5%BF%83%E7%90%86%E5%9F%BA%E7%A1%80-part1/</url>
    <content><![CDATA[<p>第二章 神经生理心理基础</p>
<ul>
<li>2.1 人脑的进化和发育</li>
<li>2.2 脑的组成</li>
<li>2.3 神经元和胶质细胞</li>
</ul>
<a id="more"></a>

<h2 id="2-1-人脑的进化和发育"><a href="#2-1-人脑的进化和发育" class="headerlink" title="2.1 人脑的进化和发育"></a>2.1 人脑的进化和发育</h2><ul>
<li>大脑重量约1.5kg，约体重的2%，大脑消耗人体总能量的20%；</li>
</ul>
<h2 id="2-2-脑的组成"><a href="#2-2-脑的组成" class="headerlink" title="2.2 脑的组成"></a>2.2 脑的组成</h2><ul>
<li>脑的切面</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/Gn2891.png" alt="大脑切面"></p>
<ul>
<li>脑的组成。婴儿摇晃症候群是白质受损的表现；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/Gn2ygP.png" alt="灰质与白质"></p>
<p><img src="https://s1.ax1x.com/2020/03/30/GnWtTe.png" alt="大脑沟回"></p>
<p>额叶与高级决策处理、意识等相关；顶叶主要与运动、感觉相关；枕叶与视觉处理相关；颞叶与听觉和平衡相关；</p>
<ul>
<li>沿用至今的大脑Brodmann分区；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GnWjpR.png" alt="大脑分区"></p>
<ul>
<li>间脑与脑干；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuP6kF.png" alt="间脑与脑干"></p>
<ul>
<li>丘脑；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuitHK.png" alt="丘脑"></p>
<ul>
<li>小脑；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/Gui43j.png" alt="小脑"></p>
<h2 id="神经元与胶质细胞"><a href="#神经元与胶质细胞" class="headerlink" title="神经元与胶质细胞"></a>神经元与胶质细胞</h2><ul>
<li>神经系统的<strong>基本功能单位</strong>是神经元（Neuron）；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuFvo8.png" alt="神经元"></p>
<ul>
<li>神经元按照功能可以分为感觉神经元、中间神经元和运动神经元。下图展示一个典型的运动神经元结构；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GukjXR.png" alt="运动神经元结构"></p>
<ul>
<li>树突棘——神经元接受信息的关键部位，位于树突上的微小分支；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuAqVP.png" alt="树突棘"></p>
<ul>
<li>胶质细胞——不产生动作电位，不传递信息，如下图中的红色和蓝色部分；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuEBIf.png" alt="胶质细胞"></p>
<ul>
<li>胶质细胞的分类；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuVNfU.png" alt="胶质细胞"></p>
<ul>
<li>胶质细胞功能，星形细胞形成血管屏障，少突胶质细胞形成髓鞘，小胶质细胞参与脑组织损伤的修复；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuVgfO.png" alt="胶质细胞功能"></p>
]]></content>
      <categories>
        <category>神经工程学</category>
      </categories>
      <tags>
        <tag>公开课笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记 4】Adding subject-independent information to subject-specific models</title>
    <url>/2020/03/29/Adding-subject-independent-information-to-subject-specific-models/</url>
    <content><![CDATA[<center>Enhancing performance of subject-specific models via subject-independent information for SSVEP-based BCIs</center>

<center>Mohammad Hadi Mehdizavareh, University of Tehran, 2020</center>

<center>PLOS ONE</center>

<p><strong>Abstract:</strong> 本文是对Extended CCA的完善和改进。eCCA提出的时候就存在一些短处，比如总共有三种数据（测试、template和sinusoidal signal），他们之间有多种计算投影矩阵和相关性的组合，但是eCCA只取了其中五种相关系数解法。为什么这样做以及是否有更好的选择，并没有讨论。且ensemble方法还未在eCCA上实现。本文作者即对上述问题进行了分析和讨论，得到了优化后的eCCA，在清华公开数据集上进行验证。实验表明，优化后的方法比eCCA效果更好，且在数据长度大于0.3s时，性能优于TRCA（ensemble应用后亦是如此）。改进的方法在sub-band较少，导联数较少以及训练样本数较少时均优于TRCA（前提是数据长度大于0.3s）。<font color=red>由于作者在论文中部分描述不是很清晰，我也没怎么看懂精髓，部分笔记详尽请见谅。</font></p>
<p><strong>Note:</strong> 能否有效利用SSVEP的相位信息，对其正确率有很大的影响；在数据长度低于0.3s时，TRCA仍然具有优势。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Basic-algorithm"><a href="#Basic-algorithm" class="headerlink" title="Basic algorithm"></a>Basic algorithm</h2><p>首先我们知道在extended CCA算法中，存在三种data，分别是：1) the test data X; 2) the template signal $X^k$ derived from averaging cross the training blocks of the k-th target; and 3) the sinusoidal signals $Y_k$.   三种信号有6种计算CCA的组合，可以得到10个典型变量（Canonical Variable, CV），利用10个典型变量计算相关系数。如下图。<font color=red>该过程仅是将eCCA所有可能进行了细化。</font></p>
<p><img src="https://s1.ax1x.com/2020/03/29/GZVbTO.png" alt="eCCA"></p>
<h2 id="Algorithm-structure"><a href="#Algorithm-structure" class="headerlink" title="Algorithm structure"></a>Algorithm structure</h2><p><img src="https://s1.ax1x.com/2020/03/29/GZlt0A.png" alt="structure"></p>
<p>从算法流程图可以看到，绿色部分是subject-independent</p>
<p>训练，灰色是subject-specific训练。</p>
<h2 id="Subject-independent-training"><a href="#Subject-independent-training" class="headerlink" title="Subject-independent training"></a>Subject-independent training</h2><p>10$CV_s$包含45种相关系数特征，这些特征中，有些特征并没有分类能力，比如$CV_9$和$CV_{10}$。本文采用Forward Selection方法选择分类效果最好的特征。对30名受试者进行7折交叉验证，得到训练受试者30名，利用这些受试者进行超参数的优化（包括两个参数：特征数量和ensemble的权重）。<strong><font color=red>为什么要对受试者进行交叉验证？</font>因为要得到适合所有受试者的特征，所以优化的目标是该特征在所有受试者上的平均正确率达到最佳。</strong></p>
<p><font color=shocking pink><strong>这里有个有意思的问题，作者论文中并没有介绍：因为涉及到超参数优化了，那么30名受试者中就需要划出验证集（validation set），不然怎么求正确率？</strong>假如作者只是没有写出这个过程，按照我的理解，最优特征应该是这样求解出来的：首先，30名受试者均需要按照blocks进行LOO交叉验证。对每一个受试者而言，可以在前5个训练blocks中得到45个相关系数特征；接下来执行FS算法的过程，即一个一个特征的选择，看其在剩下的那个block中正确率如何；最后把30个受试者正确率求平均，看正确率怎样；正确率高的说明特征较好，那么存档特征。相当于每次特征的选择都进行了一次6折的交叉验证？太麻烦了吧…</font></p>
<p>可能是我没读懂…但作者这个算法的思路还是可行的，按照这个原理就能够选出最佳的特征，如下</p>
<p><img src="https://s1.ax1x.com/2020/03/29/GZdfln.png" alt="优化后的相关系数"></p>
<p>接下来就是标准的eCCA过程，ensemble方法的公式如下</p>
<p><img src="https://s1.ax1x.com/2020/03/29/GZwVXt.png" alt="ensemble"></p>
<p>其中由于相关系数r有些对分类结果的影响不一，故前面添加了加权系数进行平衡。加权系数通过在30名训练受试者中进行GA运算得到。</p>
<p><font color=shocking pink>这里还有一个很重要的问题作者并没有描述，我们对受试者进行了7折交叉验证，那么最后只有5名受试者可以根据得到的模型求出正确率。那怎么跟TRCA结果进行对比呢？TRCA是所有人均可以直接计算呀。</font></p>
<h1 id="感触"><a href="#感触" class="headerlink" title="感触"></a>感触</h1><p>目前SSVEP识别得到公认的最优秀算法是Extended CCA和Ensemble TRCA，多数改进或新提出的方法均跟其进行对比；Filter bank和Ensemble方法似乎已经得到了普及使用。</p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>CCA</tag>
      </tags>
  </entry>
  <entry>
    <title>【神经工程学】第一章 绪论</title>
    <url>/2020/03/28/%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<blockquote>
<p>课程简介：神经工程是生物医学工程的一个分支学科，它致力于采用工程技术实现认识、修复、替代、增强或探索神经系统的特性。作为一个相对新兴的学科，尽管神经工程发展很快，但与其相关的信息和研究仍相对有限。一个制约研究队伍扩大的重要原因是我们的大学很少向本科生研究生传授有关神经科学的知识和技能。因此本导论课程的教学目的是通过对神经工程学中的一些基础问题及研究的介绍使得生物医学工程专业学生对神经工程学有初步的认识和了解。掌握神经工程学研究领域中一些基本的概念、原理和逻辑思维，为之前学习到的知识寻找应用范例，进而为有志于从事神经工程学研究的学生提供系统的知识培养。</p>
</blockquote>
<p><strong>Note：</strong>本课程由天津大学医学部明东教授主讲，学堂在线可在线观看、下载slides。本文及以后的系列博客主要更新自己在学习本课程的一些笔记和感触（<font color=shocking pink >绿色字体</font>）,方便今后复习和写论文。</p>
<p>第一章 绪论</p>
<ul>
<li>1.1 神经工程的前世今生</li>
<li>1.2 神经工程的未来</li>
</ul>
<a id="more"></a>

<h2 id="1-1-神经工程的前世今生"><a href="#1-1-神经工程的前世今生" class="headerlink" title="1.1 神经工程的前世今生"></a>1.1 神经工程的前世今生</h2><ul>
<li>2016年AlphaGo VS 李世石，2017年AlphaGo VS 柯洁 （DeepMind公司产物，目前最强是zero？）；</li>
<li>人-机混合智能的关键——神经工程技术；</li>
<li>未来的愿景是脑-机智能，目前还停留在脑-机接口层面；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAsDvn.png" alt="人机混合智能"></p>
<ul>
<li>1553年Andreas Vesalius(1514-1564)开启人体解剖学时代；</li>
<li>1861年法国外科医生、人类学家、神经病理学家Paul Broca在偏瘫半失语病人皮层中发现了控制运动语言中枢，后人为纪念他将该区域命名为Broca区，这一事件被认为是神经心理学的历史起点。<font color=shocking pink >我记得好像有个什么大脑分区表，貌似是根据德国骨科医生命名的？</font></li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAcnEV.png" alt="Broca分区"></p>
<ul>
<li><p>20世纪20年代瑞士生理学家沃尔特-鲁道夫-赫斯（1949年获生理学和医学奖）证明可以通过在猫脑里面植入电极进行电刺激，激发猫脑的行为反应（愤怒、饥饿等）。<font color=shocking pink >这可能是FES的前身了</font>；</p>
</li>
<li><p>1963年西班牙科学家何塞-德尔加多（Jose Delgado）向植入大脑的电极发送无线信号，让横冲直撞的公牛停了下来；</p>
</li>
<li><p>1963年，英国神经生理学家William Gray Walter实现了<font color=red>人类历史上第一次完整的脑-机接口技术实验</font>（意念实现幻灯片的翻页，他所设计的脑机接口系统闭环且完整）；</p>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GARC4K.png" alt="人类第一次BCI"></p>
<ul>
<li><p><strong>1973年脑机接口概念提出者Jacques J. Vidal在其文章中<font color=red>第一次给出Brain-Computer Interface 这一名词</font>，并给出了系统雏形。2000年第一次脑-机接口国际会议上Jonathan R. Wolpaw等人给出了脑-机接口的准确定义，2002年他发表的综述详细的描述了各个范式和系统性能评价指标；</strong><font color=shocking pink >BCI这个领域真是非常年轻</font>；</p>
</li>
<li><p>2008年Andrew Schwartz团队（匹兹堡大学University of Pittsburgh，美国公立常春藤）在Nature上发表文章，将电极植入猴子运动皮层，多次训练后，猴子能够通过大脑活动控制机械臂抓取食物；随后该团队开展了人体实验；</p>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAqGKx.png" alt="人体实验"></p>
<h2 id="1-2-神经工程的未来"><a href="#1-2-神经工程的未来" class="headerlink" title="1.2 神经工程的未来"></a>1.2 神经工程的未来</h2><ul>
<li>神经工程的研究内容</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GALuOP.png" alt="研究内容"></p>
<ul>
<li>神经工程的市场前景。马斯克2017年成立NeuroLink公司<font color=shocking pink >（NeuroLink主要是做植入式BCI，目前最大的成绩在于19年研发出的植入式设备）</font>，扎克伯格同年启动意念打字项目；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GALDkF.png" alt="前景"></p>
<p><img src="https://s1.ax1x.com/2020/03/28/GALH1A.png" alt="公司"></p>
<ul>
<li>深部脑刺激(Deep Brain Stimulation, DBS)是一个成功的案例，已经大量用于临床，我国也是继美国第二个拥有该临床技术的国家；</li>
<li><font color=red>群脑组网、群脑协同和群脑融合</font>。2015年七月，杜克大学发表研究成果，猴子合作作为大脑网络时比独立控制效果更优。<font color=shocking pink >这是一个非常有前景的概念，类似于环太平洋中的机甲</font>；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAjWmq.png" alt="群脑"></p>
<ul>
<li>2016年天津大学完成人类首次太空脑-机接口实验（天宫二号）；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAvMcj.png" alt="太空实验"></p>
]]></content>
      <categories>
        <category>神经工程学</category>
      </categories>
      <tags>
        <tag>公开课笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记 3】Exploiting inter-subject information for SSVEP-based BCI</title>
    <url>/2020/03/27/Exploiting-inter-subject-information-for-SSVEP-based-BCI/</url>
    <content><![CDATA[<center>Enhancing performances of SSVEP-based brain–computer interfaces via exploiting inter-subject information</center>

<center>Xiaogang Chen，清华大学，2015</center>

<center>Journal of Neural Engineering</center>

<p><strong>Abstract:</strong>  根据已有的受试者数据构造template，用于新的受试者进行分类，类似于迁移学习的思想。于是作者提出了transfer template based canonical correlation analysis (tt-CCA) ，在线实验过程中利用新的测试数据进行template更新。数据格式和清华的公开数据集一致，包括40个刺激和6个block。采用LOO进行正确率验证，即11个受试者作为source subject，用来构造transfer template。</p>
<p><strong>Note:</strong>  有迁移学习的意思，但是只是简单的受试者平均而已，这样的效果肯定没有对每个受试者进行template计算正确率高。需要注意的是，本文的方法是不需要训练集的，而且引入了在线更新的手段，使得其自适应更强。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><p>标准的CCA是没有利用到SSVEP的相位信息的（标准CCA的参考是正余弦构成的，但对这个算法本身，是对相位敏感的），如果能够在参考信号中加入相位信息，那么识别率会上升（这一点11年他们组的文章就有介绍ρ-CCA）。故后面才提出了通过训练集来构造参考信号的想法，但是又需要训练的步骤，那么CCA的最大优势就不明显了（虽然最近几年的趋势来看，更倾向于带训练的算法，毕竟还是要想正确率妥协~）。CCA有个特点，在数据长度较短的时候，由于自发脑电的影响，其效果并不理想。基于此，作者提出了training-free的结构——transfer template-based CCA (tt-CCA)  。</p>
<h2 id="tt-CCA"><a href="#tt-CCA" class="headerlink" title="tt-CCA"></a>tt-CCA</h2><h3 id="Single-channel"><a href="#Single-channel" class="headerlink" title="Single-channel"></a>Single-channel</h3><p>单通道（通常为Oz）下的tt-CCA算法结构。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Gi496H.png" alt="tt-CCA single"></p>
<h3 id="Multi-channel"><a href="#Multi-channel" class="headerlink" title="Multi-channel"></a>Multi-channel</h3><p>多通道下tt-CCA结构</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Gi48A0.png" alt="tt-CCA multi"></p>
<h2 id="在线更新方法"><a href="#在线更新方法" class="headerlink" title="在线更新方法"></a>在线更新方法</h2><p>在线的想法也比较简单，当计算出的相关系数ρ的前两个最大值之间的差异达到阈值时，便更新template。本文取得阈值为0，意思是不管怎样均更新。（其实我觉得这个超参数不是很好确定，因为SSVEP识别太玄学了，有可能某两个刺激频率就是相差特别小，这在神经机理上也能说通，毕竟每个人大脑构造都不一样。）</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Gi5tat.png" alt="ott-CCA"></p>
<p>下面给出template的更新公式，$n_k$的初值$c_0$为另一个超参数，本文设置为11，初始template由11个trial数据构成，但具体来自那几个人的不清楚（因为可以用于做template的trial有66个）。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Giom9K.png" alt="更新公式"></p>
<p>需要注意的是，两个超参数，$c_0$控制着原始template和当前EEG信号的相对重要性，thr控制着当前EEG trial可能用来更新的可能性。两者在较小时能够取得快速更新的效果。</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>答案不用说了，ott-CCA &gt; tt-CCA(multi-channel) &gt; tt-CCA(single-channel)。ott-CCA在0.5s时效果并不好，因为tt-CCA不行，所以没法提升。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GiHKjU.png" alt="tt-CCA结果"></p>
<p><img src="https://s1.ax1x.com/2020/03/27/GiHhDg.png" alt="ott-CCA结果"></p>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><p>本文只是提出了一个频率识别结构，对其中两点进行改进均可以提升整体效果。第一是更改transfer template的计算，比如采用m-CCA；第二是采用更好的频率识别方法并结合本文的模板更新措施，说白了就是对现有更好的方法进行自适应。</p>
<p><strong>毕竟这是15年的论文，目前SSVEP的成熟结构还是filter bank + ensemble + algorithm的方式，可参考电子科大19年的层次分类网络论文。</strong></p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
        <tag>SSVEP</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记 2】Alpha neurofeedback training(NFT)</title>
    <url>/2020/03/27/Alpha-neurofeedback-training-NFT/</url>
    <content><![CDATA[<center>Alpha neurofeedback training improves SSVEP-based BCI performance</center>

<center>万峰团队，澳门大学，2016</center>

<center>Journal of Neural Engineering</center>

<p><strong>Abstract:</strong> 作者通过对受试者进行神经反馈训练，使其individual alpha band (IAB) amplitudes  产生下调，从而增加受试者对SSVEP的敏感性。实验表明，经历NFT的受试者产生的SSVEP信噪比(+16.5%)和分类正确率(+20.3%)均明显提升。实验分两步，第一是发现alpha波与SSVEP之间的关系，第二根据第一步实验结果对受试者进行训练，最后对比有无训练的受试者之间差异。刺激为7~15Hz之间的10个频率，6导，算法采用标准CCA。</p>
<p><strong>Note:</strong> alpha波会对SSVEP产生影响（已有论文发现，引言中有介绍），可以通过调制alpha波增强SSVEP；引言列出了诸多关于神经反馈训练的参考论文。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="神经反馈训练的参数"><a href="#神经反馈训练的参数" class="headerlink" title="神经反馈训练的参数"></a>神经反馈训练的参数</h2><p>采用Oz导联的relative IAB amplitude作为训练参数，其计算公式为</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCHknJ.png" alt="r-IAB"></p>
<p>X(k)是睁眼信号FFT后的幅值，上述公式可以理解为：在频段0.5 ~ 30Hz范围内，LTF ~ HTF频段占比。HTF和LTF可从下图中得到</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCHMcD.png" alt="alpha波阻断"></p>
<p>图中为受试者睁闭眼各1min的结果，睁闭眼幅值的交叉点为LTF和HTF频率，图中能够明显的反应alpha阻断现象。</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><h2 id="The-relationship-between-the-resting-relative-IAB-and-the-BCI-performance"><a href="#The-relationship-between-the-resting-relative-IAB-and-the-BCI-performance" class="headerlink" title="The relationship between the resting relative IAB and the BCI performance"></a>The relationship between the resting relative IAB and the BCI performance</h2><p>相对IAB与SSVEP的SNR以及正确率呈现负相关，即在低relative IAB条件下，BCI性能会表现较好。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCqUOg.png" alt="SNR&amp;ACC"></p>
<h2 id="NFT-results"><a href="#NFT-results" class="headerlink" title="NFT results"></a>NFT results</h2><h3 id="EEG-changes"><a href="#EEG-changes" class="headerlink" title="EEG changes"></a>EEG changes</h3><p>受试者进行NFT训练，实验记录每个session相对IAB值后可以发现，受试者逐渐能够通过训练降低该参数。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCOk26.png" alt="训练进程"></p>
<h3 id="BCI性能变化"><a href="#BCI性能变化" class="headerlink" title="BCI性能变化"></a>BCI性能变化</h3><p>下图能够明显反应采用NFT训练后的BCI性能变化。其中test1为第一阶段，test2为第二阶段，控制组下test2与test1保持一致，而NFT组需要在test2前对受试者进行神经反馈训练。可以发现经过训练后的受试SNR和ACC均提升。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCOhJ1.png" alt="NFT前后结果对比"></p>
<h1 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h1><ol>
<li><p>静息态EEG活动和SSVEP的关系在之前已经有研究,包括prestimulus alpha 活动与视觉感知功能负相关等等；</p>
</li>
<li><p>目前的研究表明低频段的SSVEP与alpha之前存在着本文所述的相关性，而这种现象在高频下26–34.7 Hz  还未发现；</p>
</li>
<li><p>已有研究发现，尽管对受试者进行了NFT训练，但是一段时间后其alpha的幅值又会回到最初的水品。在本文中，相对IAB在每个session之间并没有很大的变化，但是最后却得到了性能的提升，这是为什么呢？可以用受试者的专注度和大脑神经的兴奋性来解释，即通过训练，受试者更沉着，神经活动更加兴奋了。</p>
</li>
</ol>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><p>探索在高频刺激下该工作是否成立。</p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>神经反馈训练</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记 1】Learning across multi-stimulus</title>
    <url>/2020/03/26/Learning-across-multi-stimulus/</url>
    <content><![CDATA[<center>Learning across multi-stimulus enhances target recognition methods in SSVEP-based BCIs</center>  

<center>万峰团队，澳门大学，2020</center>

<center>Journal of Neural Engineering</center>

<p><strong>Abstract:</strong> SSVEP传统的特征提取方法是利用一个target刺激构造一个权值矩阵w，而本文作者表明，可以通过目标刺激周围的几个刺激共同计算w，从而得到更好的特征提取效果，即multi-stimulus。作者将multi-stimulus和extended CCA、ensemble TRCA结合（使用了filter bank），在清华的35名受试者数据集上得到了较好的效果。</p>
<p><strong>Note:</strong> 利用非目标刺激也能增加目标识别的准确性；提供了一种不同算法的融合策略。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Learning-from-multi-stimulus-scheme"><a href="#Learning-from-multi-stimulus-scheme" class="headerlink" title="Learning from multi-stimulus scheme"></a>Learning from multi-stimulus scheme</h2><h3 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h3><p><img src="https://s1.ax1x.com/2020/03/26/G9UoV0.png" alt="G9UoV0.png"></p>
<p>可从图中看到，顶部是传统的构造空间滤波器w的方法，即一个刺激对应一个w，而本文中的观点是结合target stimulus周围几个刺激一起构造w。这里很明显，target左右刺激数为超参数。</p>
<h3 id="训练集矩阵调整"><a href="#训练集矩阵调整" class="headerlink" title="训练集矩阵调整"></a>训练集矩阵调整</h3><p>根据这个思想，我们需要对CCA和TRCA训练过程中的两个矩阵A、 B（CCA中为template和构造的sin，TRCA为template和联结矩阵）进行修改。这里通过将训练数据对角联结方法，重新构造A、B。<font color=red>（9）for CCA, (11) for TRCA.</font></p>
<p><img src="https://s1.ax1x.com/2020/03/26/G9wU8U.png" alt="G9wU8U.png"></p>
<p><img src="https://s1.ax1x.com/2020/03/26/G9wyUx.png" alt="G9wyUx.png"></p>
<p>上述构造后，两个算法的优化问题变为以下两个公式</p>
<p><img src="https://s1.ax1x.com/2020/03/26/G9w7IP.png" alt="G9w7IP.png"></p>
<p>上述问题求解较为复杂，作者通过SSVEPs share a common spatial pattern across different stimulus frequencies  现象，对u和v进行约束（<strong>这里还引入了ρ-CCA</strong>），从而求解。</p>
<h3 id="求解相关系数"><a href="#求解相关系数" class="headerlink" title="求解相关系数"></a>求解相关系数</h3><p>计算出了空间矩阵后，便可以通过下述的公式分别计算相关系数了。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/G90bwR.png" alt="G90bwR.png"></p>
<h2 id="ms-eCCA-ms-eTRCA"><a href="#ms-eCCA-ms-eTRCA" class="headerlink" title="ms-eCCA + ms-eTRCA"></a>ms-eCCA + ms-eTRCA</h2><p>TRCA是最大化inter-trial之间的协方差，而CCA是最大化inter-stimulus之间的协方差，两者结合会产生更好的效果。（想法是没问题…不过下面这个公式的结合方法也算创新？排列组合中的一种吧…）</p>
<p><font color=red>发现一个有意思的事，这里的融合其实相当于把eCCA和eTRCA的结果进行求和？只是省略了eCCA其中一项而已，但是我之前测试了并没有效果啊（CCA+MSI）？？枯了…</font></p>
<p><img src="https://s1.ax1x.com/2020/03/27/G9DsVs.png" alt="G9DsVs.png"></p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><h2 id="减少训练集"><a href="#减少训练集" class="headerlink" title="减少训练集"></a>减少训练集</h2><p>Multi-stimulus 方法可以减少训练trial数。这在eCCA上的效果尤其明显。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/G9yCgf.png" alt="G9yCgf.png"></p>
<h2 id="组合特征提取效果更佳"><a href="#组合特征提取效果更佳" class="headerlink" title="组合特征提取效果更佳"></a>组合特征提取效果更佳</h2><p>ms-eCCA + ms-eTRCA效果最佳</p>
<p><img src="https://s1.ax1x.com/2020/03/27/G9ysVH.png" alt="G9ysVH.png"></p>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><p>解决small sample size (SSS) problem，即小样本问题，这在论文Linear discriminant analysis<br>for the small sample size problem: an overview  中已有描述，可以借鉴。 </p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title>一些论文idea</title>
    <url>/2020/03/26/%E4%B8%80%E4%BA%9B%E8%AE%BA%E6%96%87idea/</url>
    <content><![CDATA[<p>记录一些不成熟的点子，以后有一定知识量了再来解释和实现。</p>
<a id="more"></a>

<ol>
<li><p>采用对抗生成网络来增加数据集，这一点在情绪脑机接口上已经实现了（参考上海交大吕宝粮老师的研究）。</p>
</li>
<li><p>迁移学习已经应用到BCI上了，但是在SSVEP上的应用并不多见？可以在清华的数据集上测试一下，进行受试者之间的自适应。</p>
</li>
<li><p>清华19年研究了疲劳对SSVEP的影响，发现不同程度的疲劳会对SSVEP的相位和幅值产生影响。刚好14年他们有一篇文章，关于相位锁定CCA的研究（ρ-CCA），是否可以根据检测疲劳从而进行相位自适应？查阅过很多论文，主要难点在疲劳和相位之间的量化分析上…</p>
</li>
</ol>
]]></content>
      <categories>
        <category>学习生活</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title>光影</title>
    <url>/2020/03/26/%E5%85%89%E5%BD%B1/</url>
    <content><![CDATA[<p>下午透过窗口缝隙照射在墙上的光。</p>
<p>…</p>
<a id="more"></a>

<p><img src="https://s1.ax1x.com/2020/03/26/GpemjJ.jpg" alt="GpemjJ.jpg"></p>
]]></content>
      <tags>
        <tag>杂记</tag>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title>CV</title>
    <url>/2020/03/26/CV/</url>
    <content><![CDATA[<p><strong>About me</strong></p>
<center>一个研究BCI的水硕</center>

<center>  一个喜欢旅拍的摄影小白  </center>

<center>一个充满希望打满鸡血的海迷</center>

<center>...</center>

<center>总之</center>

<center>天道酬勤，相信未来</center>

<a id="more"></a>

<hr>
<p><strong>Contact info</strong></p>
<p>Github: <a href="https://github.com/hisunjiang" target="_blank" rel="noopener">hisunjiang</a></p>
<p>CSDN: <a href="https://blog.csdn.net/weixin_42765703" target="_blank" rel="noopener">hi强森</a></p>
<p>Email: <a href="mailto:hisunjiang@outlook.com">hisunjiang@outlook.com</a></p>
]]></content>
  </entry>
  <entry>
    <title>记录一些好用的网站</title>
    <url>/2020/03/26/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>记录一下平时遇到的好用的网站，方便第一时间想起。先成为工具人，再学会挖井~</p>
<a id="more"></a>

<h1 id="编程区"><a href="#编程区" class="headerlink" title="编程区"></a>编程区</h1><ol>
<li><p><a href="https://www.runoob.com/" target="_blank" rel="noopener">菜鸟教程</a><br>里面包含很多编程语言的学习资料，平时复习语法时可以看一看。特别推荐里面提供的很多在线工具。</p>
</li>
<li><p><a href="https://www.liaoxuefeng.com/wiki/896043488029600/896067008724000" target="_blank" rel="noopener">廖雪峰官网Git教程</a><br>里面Git教程很详细，还有一些Python、Java的教程。</p>
</li>
<li><p><a href="https://notepad-plus-plus.org/" target="_blank" rel="noopener">Notepad++</a><br>一个非常简洁小巧的代码编辑器，支持多种源码的查看和编辑。</p>
</li>
<li><p><a href="https://typora.io" target="_blank" rel="noopener">Typora</a><br>一个很好用的Markdown编辑器。</p>
</li>
</ol>
<h1 id="学习区"><a href="#学习区" class="headerlink" title="学习区"></a>学习区</h1><ol>
<li><a href="https://www.sci-hub.tw/" target="_blank" rel="noopener">Sci-hub</a><br>大量的英文文献可以下载，包括一些已经收录但是没有刊载的。离校没有VPN时可以试试这个网站，比百度学术或者Google学术下载更方便。</li>
<li><a href="http://gen.lib.rus.ec/" target="_blank" rel="noopener">Library Genesis</a><br>主要是用来查找一些难以寻找到的英文专业著作等，当然这里面还可以下载论文。均是免费下载，不需要注册。</li>
<li><a href="http://www.6453.net/" target="_blank" rel="noopener">龙猫学术导航</a><br>学术相关的论坛（小木虫等）、资料下载途径（包括上面两个网站）等等均列出来了入口。</li>
<li><a href="http://www.pqdtcn.com/" target="_blank" rel="noopener">ProQuest</a><br>国外硕博论文全文数据库，这需要学校购买权限。</li>
<li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html" target="_blank" rel="noopener">台湾大学李宏毅老师机器学习课程</a><br>看吴恩达老师的课还是有点难以下咽，李宏毅老师的中文机器学习课更易上手，关键是老师人还是特别幽默的台湾腔。刚好今年春期课程开启，作业、video和slides都更新了。当然B站上也有人整理出来了新版的课程，不用上油管观看。</li>
<li><a href="https://ww2.mathworks.cn/matlabcentral/?s_tid=gn_mlc" target="_blank" rel="noopener">MathWorks社区</a><br>里面File Exchange 功能太强大了，这里面能找到很多网友提供的优质MATLAB程序，配合其Documentation工具包说明文档学习，编程更快。</li>
<li><a href="https://www.grammarly.com/" target="_blank" rel="noopener">Grammarly</a><br>强大的英文写作工具，自动检查语法错误并纠正。搭配<a href="http://www.phrasebank.manchester.ac.uk/" target="_blank" rel="noopener">phasebank</a>（曼彻斯特大学学术英语写作语料库，包括论文each part的写作技巧）和<a href="https://www.english-corpora.org/coca/" target="_blank" rel="noopener">coca</a>（当代美语语料库，可以查看一些词语或者短语的用法，以及在美国出版物中的使用频率）一起使用，英语写作更加标准。</li>
</ol>
<h1 id="兴趣区"><a href="#兴趣区" class="headerlink" title="兴趣区"></a>兴趣区</h1><ol>
<li><a href="https://www.pexels.com/zh-cn/" target="_blank" rel="noopener">Pexels</a><br>由摄影作者分享的素材照片，视频等。免费下载无水印，不需要注册。没事可以看看，提高一下审美。</li>
<li><a href="https://unsplash.com/" target="_blank" rel="noopener">Unsplash</a><br>高清素材照片免费下载，无需注册。</li>
<li><a href="https://www.doyoudo.com/" target="_blank" rel="noopener">doyoudo</a><br>Pr、Ps、Ae等软件的教程网。学剪辑当然还是关注B站上的一些摄影师更有收获。</li>
<li><a href="https://docsmall.com/" target="_blank" rel="noopener">docsmall</a><br>一个非常简洁清新的图片压缩、GIF压缩、PDF压缩和分割网站，无广告。</li>
</ol>
]]></content>
      <categories>
        <category>学习生活</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
</search>
