<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>关于我的博客</title>
    <url>/2020/04/02/%E5%85%B3%E4%BA%8E%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<center>欢迎来到我的吐槽空间</center>

<blockquote>
<p>突然有一天想搭一个博客记录生活中的一些琐事，看了很多教程后便着手做了这件事。作为一个前端业余爱好者，所以也没什么经验值得分享，博客是利用hexo+github/gitee搭建的，感谢原作者贡献的主题<a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank" rel="noopener">Ayer</a>。后续会逐渐添加更多的功能。</p>
</blockquote>
<p><img src="https://s1.ax1x.com/2020/04/02/GYPzvV.png" alt="ONE PIECE"></p>
<a id="more"></a>

<h2 id="这里面记录了什么呢？"><a href="#这里面记录了什么呢？" class="headerlink" title="这里面记录了什么呢？"></a>这里面记录了什么呢？</h2><h3 id="大多数是论文笔记"><a href="#大多数是论文笔记" class="headerlink" title="大多数是论文笔记"></a>大多数是论文笔记</h3><p><strong>毕竟看论文才是研究生的日常。</strong>以前喜欢论文打印出来阅读，笔记心得什么的都写在上面，后来发现离开实验室太不方便了，特别是这次疫情深有体会。本人是做脑-机接口(Brain-Computer Interface, BCI)的水硕一名，主要研究方向是稳态视觉诱发电位(Steady-State Visual Evoked Potential, SSVEP)识别<font color=red>（真不想说自己是做研究的…我这垃圾水平别玷污了研究这个神圣的词）</font>。所以呢，论文笔记关于BCI/SSVEP的多一些。当然，还会更新一些信号处理、机器学习的内容。我觉得用博客做论文笔记真是一件很必要的事，能够转述别人的论文成果，能够总结其中的要点，能够开一些脑洞……对自己的提升都会有很大帮助。毕竟，不能脱口而出乃至授人以渔的知识，都不是自己已经掌握的知识。这里的笔记记录主要是方便自己思考和回顾，如果想看高质量的人工智能论文解读和推荐，转<a href="http://www.paperweekly.site/" target="_blank" rel="noopener">Paperweekly</a>。</p>
<h3 id="部分为一些杂记"><a href="#部分为一些杂记" class="headerlink" title="部分为一些杂记"></a>部分为一些杂记</h3><p>包括一些心灵鸡汤和随笔。</p>
<p><strong>学习真是一件很神奇的事，你会越来越发现自己有多无知又有多值得努力。</strong>我爱我的母校西大，但是我却遗憾自己在那里没能接受到前沿的教育，这可能是大多数高校存在的问题。本科的时候是在电子科创实验室，主要做一些控制方面的东西，也得过一些全国的奖，什么电赛、全国机器人大赛之类的。后来参加的比赛多了，见识过其他学校的同学水平，那时候才意识到自己眼界和能力有多欠缺。那种感觉就好像是你在使用旧式步枪，而对方已经开始应用自动制导了一样。虽然你正中十环，但对方给你的震慑力远比这微不足道的成绩更值得留意。那时候我开始对AI这个行业抱有强烈的兴趣，后来看过一些零星的报道和书籍，这里推荐微软亚洲研究院院长洪小文2017年在清华的报告：<a href="https://www.msra.cn/zh-cn/news/features/hon-the-brief-history-of-intelligence-1" target="_blank" rel="noopener">以科学的方式赤裸裸地剖析人工智能</a>。</p>
<p><strong>保持好奇心和激情是一件很难却很酷的事。</strong>我记得推免的时候系主任问我以后的规划，我说我想学智能算法让自己做的机器人有灵魂，哈哈哈，现在想想这种话也好意思在这么多老师面前说出口。后来来到了CQU，套用实验室师兄毕业论文中的致谢以表达我对导师们的感激之情：先生不以余学术浅陋，将余纳入门墙，从此言传身教，亲生相授。学生不敏，未习得先生一二，然耳濡目染，亦有所获。虽然自己很菜，但所幸对现在的研究方向颇为感兴趣，希望勤勤恳恳有所获。BCI以后肯定会很火，毕竟我的偶像Elon Musk也在17年创办了Neruolink。</p>
<h3 id="还有一些关于爱好"><a href="#还有一些关于爱好" class="headerlink" title="还有一些关于爱好"></a>还有一些关于爱好</h3><p>以后会在博客中开专栏更摄影的东西。</p>
<p><strong>一定要开始学剪辑了。</strong>感觉没点爱好生活好像失去了一些灵魂要素。都在B站观望摄影好多年了，迟迟不开始主要是因为穷……等着今年一定要把α6400或者M6 mark II买了。会旅拍真是一件很酷的技能，无论是转场、运镜还是剪辑，早点熟练就可以早点记录下一些精彩的故事。</p>
<p>&nbsp; &nbsp;</p>
<p>“人的梦想是不会终止的”</p>
<p>对喜欢的事多一点偏执和理想主义挺好</p>
<p>以上，是关于我的博客的介绍，亦是来自内心纠结的自述</p>
]]></content>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>Cross-Subject Transfer Learning based SSVEP</title>
    <url>/2020/04/01/Cross-Subject-Transfer-Learning-based-SSVEP/</url>
    <content><![CDATA[<center>Cross-Subject Transfer Learning Improves the Practicality of
    Real-World Applications of Brain-Computer Interfaces</center>

<center>Kuan-Jung Chiang, 加州大学圣迭戈分校, 2019</center>

<center>9th International IEEE EMBS Conference on Neural Engineering</center>

<p><strong>Abstract:</strong> 通过其他受试者的数据对现有测试者template进行增广，并利用TRCA验证增广前后的分类性能。其中，作者利用最小二乘变换(Least-Squares Transformation, LST)  将其他人的数据变换为当前受试者的template，从而增加训练集。实验测试了template增广前后以及LST使用前后的效果，实验表明，当受试者template trial数较少（即训练集数量较小）时，LST具有明显的优势。</p>
<p><strong>Note:</strong>  利用现有数据实现受试者之间的template迁移，本文是通过LST将其他受试者数据变换到当前受试者的数据空间上<font color=red>（类似于增大其他人数据与当前受试者之间的相似度）</font>;内含部分SSVEP中迁移学习的文献。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Least-Squares-Transformation-LST"><a href="#Least-Squares-Transformation-LST" class="headerlink" title="Least-Squares Transformation (LST)"></a>Least-Squares Transformation (LST)</h2><p>本文的整体出发点是认为受试者之间的SSVEP信号存在变换关系，即可以通过变换矩阵P将已有受试者数据$\acute{x}$变换为与当前受试者$x$一致，即$x=P\acute{x}$。其中变换矩阵P可以通过channel-wise最小二乘回归求得，见图</p>
<p><img src="https://s1.ax1x.com/2020/04/01/G16zrt.png" alt="LST"></p>
<p>在实际应用过程中，当前受试者的数据$\bar{x}$根据训练集数量进行trial平均,将existing subjects的$N_t$个trial数据按通道进行LST计算，最后得到变换后的$N_t$个trial数据$\acute{x}_{trans}$。</p>
<h2 id="Three-schemes-for-SSVEP-decoding"><a href="#Three-schemes-for-SSVEP-decoding" class="headerlink" title="Three schemes for SSVEP decoding"></a>Three schemes for SSVEP decoding</h2><p>本文对比了subjects迁移前后，使用LST计算template前后的分类效果，三种scheme：Baseline、w/o LST和w/LST如下图</p>
<p><img src="https://s1.ax1x.com/2020/04/01/G1gl0P.png" alt="schemes"></p>
<p>实验数据分为8 subjects * 2 sessions * 15 blocks * 40 targets，故对每个session包含15个trial per stimulus，上图亦是针对每个session而言，将15个trial划分成5个训练（生成template）和10个测试，并重复了10次随机划分。8个受试者之间执行了LOO。</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p><img src="https://s1.ax1x.com/2020/04/01/G12Fjs.png" alt="结果"></p>
<p><img src="https://s1.ax1x.com/2020/04/01/G12aCD.png" alt="结果"></p>
<p>从图中可以看到</p>
<ul>
<li><font color=red>当template size较小时，通过其他受试者数据的引入，能够提高分类正确率；</font></li>
<li>随着template size的增加（到5时，即每个刺激包含5个训练样本），w/LST方法与Baseline方法无显著差异；</li>
<li>w/LST方法具有显著优势，特别是当受试者的训练数据不足时。</li>
</ul>
<h1 id="感触"><a href="#感触" class="headerlink" title="感触"></a>感触</h1><p>当前SSVEP的频率识别多是根据相关性的方法，其中的关键问题是template的获取，故本文研究的迁移学习思想也是针对template的改进，将已有数据向测试受试者的数据进行逼近。<font color=shocking pink><strong>是否存在更好的特征迁移方法？比如将其他受试者的数据和当前受试者的数据变换到相同的数据空间。（本文是通过特征变换方式减少源域和目标域的差异，采用统一变换到相同特征空间呢？）</strong></font></p>
]]></content>
      <categories>
        <category>论文笔记</category>
        <category>BCI</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>云</title>
    <url>/2020/03/31/%E4%BA%91/</url>
    <content><![CDATA[<p>在门前拍到看着很舒服的云。</p>
<p><img src="https://s1.ax1x.com/2020/03/31/GMvG60.png" alt="云"></p>
<a id="more"></a>

<p>突然感觉到了力不从心，无论是对学习的规划，还是对自己爱好的培养，都没能得到满足和平衡。上午看了中科院王晋东博士对迁移学习的总结，里面有句引用写得真好：<strong>吾生也有涯，而知也无涯。以有涯随无涯，殆已。</strong>可能自己需要多一些理性的思考，对自己努力的方向有更清晰的认识……</p>
]]></content>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction</title>
    <url>/2020/03/31/Introduction/</url>
    <content><![CDATA[<blockquote>
<p>课程简介：本课程是国立台湾大学<a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html" target="_blank" rel="noopener">李宏毅(Hung-yi Lee)老师</a>2020年春期课程，课程内容包含回归、分类、深度学习、迁移学习、强化学习、元学习等重要内容。<img src="https://s1.ax1x.com/2020/03/31/GK1wfs.png" alt="知识图谱"></p>
</blockquote>
<p><strong>Note:</strong> 作为非计算机科班出生的理工科学生，能够找到一个适合自己学习的机器学习课程并不容易。以前常自己啃西瓜书，后来发现没有系统的接受课程训练，对ML的理解并不深入。此外，李老师的台湾腔以及幽默的授课风格真让人爱了。本文及后续博文是关于本课程的学习笔记，其中<font color=shocking pink >绿色部分</font>是自己不成熟的思考。</p>
<a id="more"></a>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>机器学习的任务就是找出输入与输出之前的函数关系，其内容不仅包含回归和分类，还包括generation（GAN, seq2seq等）；</li>
<li>最新的Alpha zero应用的是强化学习；</li>
<li>函数的寻找方法——梯度下降；</li>
</ul>
<p><strong>下面是一些前沿研究课题</strong></p>
<ul>
<li>Explainable AI: 我们需要对机器为什么做出一个决策做分析；</li>
<li>Adversarial Attack: 我们所设计的模型都具有一定的鲁棒性，即在噪声的干扰下能够保持较好的性能。但是如果我们加入的噪声是经过一定修饰的，那我们的机器会做出什么样的决策呢？</li>
<li>Network Compression: 如果我们设计的模型很大，那如何把它嵌入到类似手机一样的小设备中？</li>
<li>Anomaly Detection: 如果把做好的模型用到线上，输入样本中出现了训练阶段从来未遇到过的样本类型（比如做动物识别，但是放入了汽车的照片），那机器怎么知道它不知道这个样本是什么的哲学问题；</li>
<li>迁移学习（这里推荐中科院博士整理的<a href="http://transferlearning.xyz/#0latest-publications-%e6%9c%80%e6%96%b0%e8%ae%ba%e6%96%87" target="_blank" rel="noopener">超全的资料</a>）；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/31/GK0aA1.png" alt="迁移学习"></p>
<ul>
<li><font color=red>Meta Learning:</font> 学习如何学习，赋予机器学习如何学习的能力。机器学习是写一段程序让机器具有学习能力，而元学习是写一段程序，这个程序可以用来写另外一段程序，使之具有学习功能；</li>
<li>Life-long Learning: 让机器不断地学习，使之能够处理的任务不断增加；</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>公开课学习</tag>
      </tags>
  </entry>
  <entry>
    <title>第二章 神经生理心理基础 part1</title>
    <url>/2020/03/30/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%94%9F%E7%90%86%E5%BF%83%E7%90%86%E5%9F%BA%E7%A1%80-part1/</url>
    <content><![CDATA[<p>第二章 神经生理心理基础</p>
<ul>
<li>2.1 人脑的进化和发育</li>
<li>2.2 脑的组成</li>
<li>2.3 神经元和胶质细胞</li>
</ul>
<a id="more"></a>

<h2 id="2-1-人脑的进化和发育"><a href="#2-1-人脑的进化和发育" class="headerlink" title="2.1 人脑的进化和发育"></a>2.1 人脑的进化和发育</h2><ul>
<li>大脑重量约1.5kg，约体重的2%，大脑消耗人体总能量的20%；</li>
</ul>
<h2 id="2-2-脑的组成"><a href="#2-2-脑的组成" class="headerlink" title="2.2 脑的组成"></a>2.2 脑的组成</h2><ul>
<li>脑的切面</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/Gn2891.png" alt="大脑切面"></p>
<ul>
<li>脑的组成。婴儿摇晃症候群是白质受损的表现；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/Gn2ygP.png" alt="灰质与白质"></p>
<p><img src="https://s1.ax1x.com/2020/03/30/GnWtTe.png" alt="大脑沟回"></p>
<p>额叶与高级决策处理、意识等相关；顶叶主要与运动、感觉相关；枕叶与视觉处理相关；颞叶与听觉和平衡相关；</p>
<ul>
<li>沿用至今的大脑Brodmann分区；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GnWjpR.png" alt="大脑分区"></p>
<ul>
<li>间脑与脑干；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuP6kF.png" alt="间脑与脑干"></p>
<ul>
<li>丘脑；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuitHK.png" alt="丘脑"></p>
<ul>
<li>小脑；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/Gui43j.png" alt="小脑"></p>
<h2 id="神经元与胶质细胞"><a href="#神经元与胶质细胞" class="headerlink" title="神经元与胶质细胞"></a>神经元与胶质细胞</h2><ul>
<li>神经系统的<strong>基本功能单位</strong>是神经元（Neuron）；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuFvo8.png" alt="神经元"></p>
<ul>
<li>神经元按照功能可以分为感觉神经元、中间神经元和运动神经元。下图展示一个典型的运动神经元结构；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GukjXR.png" alt="运动神经元结构"></p>
<ul>
<li>树突棘——神经元接受信息的关键部位，位于树突上的微小分支；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuAqVP.png" alt="树突棘"></p>
<ul>
<li>胶质细胞——不产生动作电位，不传递信息，如下图中的红色和蓝色部分；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuEBIf.png" alt="胶质细胞"></p>
<ul>
<li>胶质细胞的分类；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuVNfU.png" alt="胶质细胞"></p>
<ul>
<li>胶质细胞功能，星形细胞形成血管屏障，少突胶质细胞形成髓鞘，小胶质细胞参与脑组织损伤的修复；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/30/GuVgfO.png" alt="胶质细胞功能"></p>
]]></content>
      <categories>
        <category>神经工程学</category>
      </categories>
      <tags>
        <tag>公开课笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Adding subject-independent information to subject-specific models</title>
    <url>/2020/03/29/Adding-subject-independent-information-to-subject-specific-models/</url>
    <content><![CDATA[<center>Enhancing performance of subject-specific models via subject-independent information for SSVEP-based BCIs</center>

<center>Mohammad Hadi Mehdizavareh, University of Tehran, 2020</center>

<center>PLOS ONE</center>

<p><strong>Abstract:</strong> 本文是对Extended CCA的完善和改进。eCCA提出的时候就存在一些短处，比如总共有三种数据（测试、template和sinusoidal signal），他们之间有多种计算投影矩阵和相关性的组合，但是eCCA只取了其中五种相关系数解法。为什么这样做以及是否有更好的选择，并没有讨论。且ensemble方法还未在eCCA上实现。本文作者即对上述问题进行了分析和讨论，得到了优化后的eCCA，在清华公开数据集上进行验证。实验表明，优化后的方法比eCCA效果更好，且在数据长度大于0.3s时，性能优于TRCA（ensemble应用后亦是如此）。改进的方法在sub-band较少，导联数较少以及训练样本数较少时均优于TRCA（前提是数据长度大于0.3s）。<font color=red>由于作者在论文中部分描述不是很清晰，我也没怎么看懂精髓，部分笔记详尽请见谅。</font></p>
<p><strong>Note:</strong> 能否有效利用SSVEP的相位信息，对其正确率有很大的影响；在数据长度低于0.3s时，TRCA仍然具有优势。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Basic-algorithm"><a href="#Basic-algorithm" class="headerlink" title="Basic algorithm"></a>Basic algorithm</h2><p>首先我们知道在extended CCA算法中，存在三种data，分别是：1) the test data X; 2) the template signal $X^k$ derived from averaging cross the training blocks of the k-th target; and 3) the sinusoidal signals $Y_k$.   三种信号有6种计算CCA的组合，可以得到10个典型变量（Canonical Variable, CV），利用10个典型变量计算相关系数。如下图。<font color=red>该过程仅是将eCCA所有可能进行了细化。</font></p>
<p><img src="https://s1.ax1x.com/2020/03/29/GZVbTO.png" alt="eCCA"></p>
<h2 id="Algorithm-structure"><a href="#Algorithm-structure" class="headerlink" title="Algorithm structure"></a>Algorithm structure</h2><p><img src="https://s1.ax1x.com/2020/03/29/GZlt0A.png" alt="structure"></p>
<p>从算法流程图可以看到，绿色部分是subject-independent</p>
<p>训练，灰色是subject-specific训练。</p>
<h2 id="Subject-independent-training"><a href="#Subject-independent-training" class="headerlink" title="Subject-independent training"></a>Subject-independent training</h2><p>10$CV_s$包含45种相关系数特征，这些特征中，有些特征并没有分类能力，比如$CV_9$和$CV_{10}$。本文采用Forward Selection方法选择分类效果最好的特征。对30名受试者进行7折交叉验证，得到训练受试者30名，利用这些受试者进行超参数的优化（包括两个参数：特征数量和ensemble的权重）。<strong><font color=red>为什么要对受试者进行交叉验证？</font>因为要得到适合所有受试者的特征，所以优化的目标是该特征在所有受试者上的平均正确率达到最佳。</strong></p>
<p><font color=shocking pink><strong>这里有个有意思的问题，作者论文中并没有介绍：因为涉及到超参数优化了，那么30名受试者中就需要划出验证集（validation set），不然怎么求正确率？</strong>假如作者只是没有写出这个过程，按照我的理解，最优特征应该是这样求解出来的：首先，30名受试者均需要按照blocks进行LOO交叉验证。对每一个受试者而言，可以在前5个训练blocks中得到45个相关系数特征；接下来执行FS算法的过程，即一个一个特征的选择，看其在剩下的那个block中正确率如何；最后把30个受试者正确率求平均，看正确率怎样；正确率高的说明特征较好，那么存档特征。相当于每次特征的选择都进行了一次6折的交叉验证？太麻烦了吧…</font></p>
<p>可能是我没读懂…但作者这个算法的思路还是可行的，按照这个原理就能够选出最佳的特征，如下</p>
<p><img src="https://s1.ax1x.com/2020/03/29/GZdfln.png" alt="优化后的相关系数"></p>
<p>接下来就是标准的eCCA过程，ensemble方法的公式如下</p>
<p><img src="https://s1.ax1x.com/2020/03/29/GZwVXt.png" alt="ensemble"></p>
<p>其中由于相关系数r有些对分类结果的影响不一，故前面添加了加权系数进行平衡。加权系数通过在30名训练受试者中进行GA运算得到。</p>
<p><font color=shocking pink>这里还有一个很重要的问题作者并没有描述，我们对受试者进行了7折交叉验证，那么最后只有5名受试者可以根据得到的模型求出正确率。那怎么跟TRCA结果进行对比呢？TRCA是所有人均可以直接计算呀。</font></p>
<h1 id="感触"><a href="#感触" class="headerlink" title="感触"></a>感触</h1><p>目前SSVEP识别得到公认的最优秀算法是Extended CCA和Ensemble TRCA，多数改进或新提出的方法均跟其进行对比；Filter bank和Ensemble方法似乎已经得到了普及使用。</p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>CCA</tag>
      </tags>
  </entry>
  <entry>
    <title>第一章 绪论</title>
    <url>/2020/03/28/%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<blockquote>
<p>课程简介：神经工程是生物医学工程的一个分支学科，它致力于采用工程技术实现认识、修复、替代、增强或探索神经系统的特性。作为一个相对新兴的学科，尽管神经工程发展很快，但与其相关的信息和研究仍相对有限。一个制约研究队伍扩大的重要原因是我们的大学很少向本科生研究生传授有关神经科学的知识和技能。因此本导论课程的教学目的是通过对神经工程学中的一些基础问题及研究的介绍使得生物医学工程专业学生对神经工程学有初步的认识和了解。掌握神经工程学研究领域中一些基本的概念、原理和逻辑思维，为之前学习到的知识寻找应用范例，进而为有志于从事神经工程学研究的学生提供系统的知识培养。</p>
</blockquote>
<p><strong>Note：</strong>本课程由天津大学医学部明东教授主讲，学堂在线可在线观看、下载slides。本文及以后的系列博客主要更新自己在学习本课程的一些笔记和感触（<font color=shocking pink >绿色字体</font>）,方便今后复习和写论文。</p>
<p>第一章 绪论</p>
<ul>
<li>1.1 神经工程的前世今生</li>
<li>1.2 神经工程的未来</li>
</ul>
<a id="more"></a>

<h2 id="1-1-神经工程的前世今生"><a href="#1-1-神经工程的前世今生" class="headerlink" title="1.1 神经工程的前世今生"></a>1.1 神经工程的前世今生</h2><ul>
<li>2016年AlphaGo VS 李世石，2017年AlphaGo VS 柯洁 （DeepMind公司产物，目前最强是zero？）；</li>
<li>人-机混合智能的关键——神经工程技术；</li>
<li>未来的愿景是脑-机智能，目前还停留在脑-机接口层面；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAsDvn.png" alt="人机混合智能"></p>
<ul>
<li>1553年Andreas Vesalius(1514-1564)开启人体解剖学时代；</li>
<li>1861年法国外科医生、人类学家、神经病理学家Paul Broca在偏瘫半失语病人皮层中发现了控制运动语言中枢，后人为纪念他将该区域命名为Broca区，这一事件被认为是神经心理学的历史起点。<font color=shocking pink >我记得好像有个什么大脑分区表，貌似是根据德国骨科医生命名的？</font></li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAcnEV.png" alt="Broca分区"></p>
<ul>
<li><p>20世纪20年代瑞士生理学家沃尔特-鲁道夫-赫斯（1949年获生理学和医学奖）证明可以通过在猫脑里面植入电极进行电刺激，激发猫脑的行为反应（愤怒、饥饿等）。<font color=shocking pink >这可能是FES的前身了</font>；</p>
</li>
<li><p>1963年西班牙科学家何塞-德尔加多（Jose Delgado）向植入大脑的电极发送无线信号，让横冲直撞的公牛停了下来；</p>
</li>
<li><p>1963年，英国神经生理学家William Gray Walter实现了<font color=red>人类历史上第一次完整的脑-机接口技术实验</font>（意念实现幻灯片的翻页，他所设计的脑机接口系统闭环且完整）；</p>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GARC4K.png" alt="人类第一次BCI"></p>
<ul>
<li><p><strong>1973年脑机接口概念提出者Jacques J. Vidal在其文章中<font color=red>第一次给出Brain-Computer Interface 这一名词</font>，并给出了系统雏形。2000年第一次脑-机接口国际会议上Jonathan R. Wolpaw等人给出了脑-机接口的准确定义，2002年他发表的综述详细的描述了各个范式和系统性能评价指标；</strong><font color=shocking pink >BCI这个领域真是非常年轻</font>；</p>
</li>
<li><p>2008年Andrew Schwartz团队（匹兹堡大学University of Pittsburgh，美国公立常春藤）在Nature上发表文章，将电极植入猴子运动皮层，多次训练后，猴子能够通过大脑活动控制机械臂抓取食物；随后该团队开展了人体实验；</p>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAqGKx.png" alt="人体实验"></p>
<h2 id="1-2-神经工程的未来"><a href="#1-2-神经工程的未来" class="headerlink" title="1.2 神经工程的未来"></a>1.2 神经工程的未来</h2><ul>
<li>神经工程的研究内容</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GALuOP.png" alt="研究内容"></p>
<ul>
<li>神经工程的市场前景。马斯克2017年成立NeuroLink公司<font color=shocking pink >（NeuroLink主要是做植入式BCI，目前最大的成绩在于19年研发出的植入式设备）</font>，扎克伯格同年启动意念打字项目；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GALDkF.png" alt="前景"></p>
<p><img src="https://s1.ax1x.com/2020/03/28/GALH1A.png" alt="公司"></p>
<ul>
<li>深部脑刺激(Deep Brain Stimulation, DBS)是一个成功的案例，已经大量用于临床，我国也是继美国第二个拥有该临床技术的国家；</li>
<li><font color=red>群脑组网、群脑协同和群脑融合</font>。2015年七月，杜克大学发表研究成果，猴子合作作为大脑网络时比独立控制效果更优。<font color=shocking pink >这是一个非常有前景的概念，类似于环太平洋中的机甲</font>；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAjWmq.png" alt="群脑"></p>
<ul>
<li>2016年天津大学完成人类首次太空脑-机接口实验（天宫二号）；</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/03/28/GAvMcj.png" alt="太空实验"></p>
]]></content>
      <categories>
        <category>神经工程学</category>
      </categories>
      <tags>
        <tag>公开课笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Exploiting inter-subject information for SSVEP-based BCI</title>
    <url>/2020/03/27/Exploiting-inter-subject-information-for-SSVEP-based-BCI/</url>
    <content><![CDATA[<center>Enhancing performances of SSVEP-based brain–computer interfaces via exploiting inter-subject information</center>

<center>Xiaogang Chen，清华大学，2015</center>

<center>Journal of Neural Engineering</center>

<p><strong>Abstract:</strong>  根据已有的受试者数据构造template，用于新的受试者进行分类，类似于迁移学习的思想。于是作者提出了transfer template based canonical correlation analysis (tt-CCA) ，在线实验过程中利用新的测试数据进行template更新。数据格式和清华的公开数据集一致，包括40个刺激和6个block。采用LOO进行正确率验证，即11个受试者作为source subject，用来构造transfer template。</p>
<p><strong>Note:</strong>  有迁移学习的意思，但是只是简单的受试者平均而已，这样的效果肯定没有对每个受试者进行template计算正确率高。需要注意的是，本文的方法是不需要训练集的，而且引入了在线更新的手段，使得其自适应更强。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><p>标准的CCA是没有利用到SSVEP的相位信息的（标准CCA的参考是正余弦构成的，但对这个算法本身，是对相位敏感的），如果能够在参考信号中加入相位信息，那么识别率会上升（这一点11年他们组的文章就有介绍ρ-CCA）。故后面才提出了通过训练集来构造参考信号的想法，但是又需要训练的步骤，那么CCA的最大优势就不明显了（虽然最近几年的趋势来看，更倾向于带训练的算法，毕竟还是要想正确率妥协~）。CCA有个特点，在数据长度较短的时候，由于自发脑电的影响，其效果并不理想。基于此，作者提出了training-free的结构——transfer template-based CCA (tt-CCA)  。</p>
<h2 id="tt-CCA"><a href="#tt-CCA" class="headerlink" title="tt-CCA"></a>tt-CCA</h2><h3 id="Single-channel"><a href="#Single-channel" class="headerlink" title="Single-channel"></a>Single-channel</h3><p>单通道（通常为Oz）下的tt-CCA算法结构。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Gi496H.png" alt="tt-CCA single"></p>
<h3 id="Multi-channel"><a href="#Multi-channel" class="headerlink" title="Multi-channel"></a>Multi-channel</h3><p>多通道下tt-CCA结构</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Gi48A0.png" alt="tt-CCA multi"></p>
<h2 id="在线更新方法"><a href="#在线更新方法" class="headerlink" title="在线更新方法"></a>在线更新方法</h2><p>在线的想法也比较简单，当计算出的相关系数ρ的前两个最大值之间的差异达到阈值时，便更新template。本文取得阈值为0，意思是不管怎样均更新。（其实我觉得这个超参数不是很好确定，因为SSVEP识别太玄学了，有可能某两个刺激频率就是相差特别小，这在神经机理上也能说通，毕竟每个人大脑构造都不一样。）</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Gi5tat.png" alt="ott-CCA"></p>
<p>下面给出template的更新公式，$n_k$的初值$c_0$为另一个超参数，本文设置为11，初始template由11个trial数据构成，但具体来自那几个人的不清楚（因为可以用于做template的trial有66个）。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/Giom9K.png" alt="更新公式"></p>
<p>需要注意的是，两个超参数，$c_0$控制着原始template和当前EEG信号的相对重要性，thr控制着当前EEG trial可能用来更新的可能性。两者在较小时能够取得快速更新的效果。</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>答案不用说了，ott-CCA &gt; tt-CCA(multi-channel) &gt; tt-CCA(single-channel)。ott-CCA在0.5s时效果并不好，因为tt-CCA不行，所以没法提升。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GiHKjU.png" alt="tt-CCA结果"></p>
<p><img src="https://s1.ax1x.com/2020/03/27/GiHhDg.png" alt="ott-CCA结果"></p>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><p>本文只是提出了一个频率识别结构，对其中两点进行改进均可以提升整体效果。第一是更改transfer template的计算，比如采用m-CCA；第二是采用更好的频率识别方法并结合本文的模板更新措施，说白了就是对现有更好的方法进行自适应。</p>
<p><strong>毕竟这是15年的论文，目前SSVEP的成熟结构还是filter bank + ensemble + algorithm的方式，可参考电子科大19年的层次分类网络论文。</strong></p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Alpha neurofeedback training(NFT)</title>
    <url>/2020/03/27/Alpha-neurofeedback-training-NFT/</url>
    <content><![CDATA[<center>Alpha neurofeedback training improves SSVEP-based BCI performance</center>

<center>万峰团队，澳门大学，2016</center>

<center>Journal of Neural Engineering</center>

<p><strong>Abstract:</strong> 作者通过对受试者进行神经反馈训练，使其individual alpha band (IAB) amplitudes  产生下调，从而增加受试者对SSVEP的敏感性。实验表明，经历NFT的受试者产生的SSVEP信噪比(+16.5%)和分类正确率(+20.3%)均明显提升。实验分两步，第一是发现alpha波与SSVEP之间的关系，第二根据第一步实验结果对受试者进行训练，最后对比有无训练的受试者之间差异。刺激为7~15Hz之间的10个频率，6导，算法采用标准CCA。</p>
<p><strong>Note:</strong> alpha波会对SSVEP产生影响（已有论文发现，引言中有介绍），可以通过调制alpha波增强SSVEP；引言列出了诸多关于神经反馈训练的参考论文。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="神经反馈训练的参数"><a href="#神经反馈训练的参数" class="headerlink" title="神经反馈训练的参数"></a>神经反馈训练的参数</h2><p>采用Oz导联的relative IAB amplitude作为训练参数，其计算公式为</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCHknJ.png" alt="r-IAB"></p>
<p>X(k)是睁眼信号FFT后的幅值，上述公式可以理解为：在频段0.5 ~ 30Hz范围内，LTF ~ HTF频段占比。HTF和LTF可从下图中得到</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCHMcD.png" alt="alpha波阻断"></p>
<p>图中为受试者睁闭眼各1min的结果，睁闭眼幅值的交叉点为LTF和HTF频率，图中能够明显的反应alpha阻断现象。</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><h2 id="The-relationship-between-the-resting-relative-IAB-and-the-BCI-performance"><a href="#The-relationship-between-the-resting-relative-IAB-and-the-BCI-performance" class="headerlink" title="The relationship between the resting relative IAB and the BCI performance"></a>The relationship between the resting relative IAB and the BCI performance</h2><p>相对IAB与SSVEP的SNR以及正确率呈现负相关，即在低relative IAB条件下，BCI性能会表现较好。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCqUOg.png" alt="SNR&amp;ACC"></p>
<h2 id="NFT-results"><a href="#NFT-results" class="headerlink" title="NFT results"></a>NFT results</h2><h3 id="EEG-changes"><a href="#EEG-changes" class="headerlink" title="EEG changes"></a>EEG changes</h3><p>受试者进行NFT训练，实验记录每个session相对IAB值后可以发现，受试者逐渐能够通过训练降低该参数。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCOk26.png" alt="训练进程"></p>
<h3 id="BCI性能变化"><a href="#BCI性能变化" class="headerlink" title="BCI性能变化"></a>BCI性能变化</h3><p>下图能够明显反应采用NFT训练后的BCI性能变化。其中test1为第一阶段，test2为第二阶段，控制组下test2与test1保持一致，而NFT组需要在test2前对受试者进行神经反馈训练。可以发现经过训练后的受试SNR和ACC均提升。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/GCOhJ1.png" alt="NFT前后结果对比"></p>
<h1 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h1><ol>
<li><p>静息态EEG活动和SSVEP的关系在之前已经有研究,包括prestimulus alpha 活动与视觉感知功能负相关等等；</p>
</li>
<li><p>目前的研究表明低频段的SSVEP与alpha之前存在着本文所述的相关性，而这种现象在高频下26–34.7 Hz  还未发现；</p>
</li>
<li><p>已有研究发现，尽管对受试者进行了NFT训练，但是一段时间后其alpha的幅值又会回到最初的水品。在本文中，相对IAB在每个session之间并没有很大的变化，但是最后却得到了性能的提升，这是为什么呢？可以用受试者的专注度和大脑神经的兴奋性来解释，即通过训练，受试者更沉着，神经活动更加兴奋了。</p>
</li>
</ol>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><p>探索在高频刺激下该工作是否成立。</p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>神经反馈训练</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning across multi-stimulus</title>
    <url>/2020/03/26/Learning-across-multi-stimulus/</url>
    <content><![CDATA[<center>Learning across multi-stimulus enhances target recognition methods in SSVEP-based BCIs</center>  

<center>万峰团队，澳门大学，2020</center>

<center>Journal of Neural Engineering</center>

<p><strong>Abstract:</strong> SSVEP传统的特征提取方法是利用一个target刺激构造一个权值矩阵w，而本文作者表明，可以通过目标刺激周围的几个刺激共同计算w，从而得到更好的特征提取效果，即multi-stimulus。作者将multi-stimulus和extended CCA、ensemble TRCA结合（使用了filter bank），在清华的35名受试者数据集上得到了较好的效果。</p>
<p><strong>Note:</strong> 利用非目标刺激也能增加目标识别的准确性；提供了一种不同算法的融合策略。</p>
<a id="more"></a>

<h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="Learning-from-multi-stimulus-scheme"><a href="#Learning-from-multi-stimulus-scheme" class="headerlink" title="Learning from multi-stimulus scheme"></a>Learning from multi-stimulus scheme</h2><h3 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h3><p><img src="https://s1.ax1x.com/2020/03/26/G9UoV0.png" alt="G9UoV0.png"></p>
<p>可从图中看到，顶部是传统的构造空间滤波器w的方法，即一个刺激对应一个w，而本文中的观点是结合target stimulus周围几个刺激一起构造w。这里很明显，target左右刺激数为超参数。</p>
<h3 id="训练集矩阵调整"><a href="#训练集矩阵调整" class="headerlink" title="训练集矩阵调整"></a>训练集矩阵调整</h3><p>根据这个思想，我们需要对CCA和TRCA训练过程中的两个矩阵A、 B（CCA中为template和构造的sin，TRCA为template和联结矩阵）进行修改。这里通过将训练数据对角联结方法，重新构造A、B。<font color=red>（9）for CCA, (11) for TRCA.</font></p>
<p><img src="https://s1.ax1x.com/2020/03/26/G9wU8U.png" alt="G9wU8U.png"></p>
<p><img src="https://s1.ax1x.com/2020/03/26/G9wyUx.png" alt="G9wyUx.png"></p>
<p>上述构造后，两个算法的优化问题变为以下两个公式</p>
<p><img src="https://s1.ax1x.com/2020/03/26/G9w7IP.png" alt="G9w7IP.png"></p>
<p>上述问题求解较为复杂，作者通过SSVEPs share a common spatial pattern across different stimulus frequencies  现象，对u和v进行约束（<strong>这里还引入了ρ-CCA</strong>），从而求解。</p>
<h3 id="求解相关系数"><a href="#求解相关系数" class="headerlink" title="求解相关系数"></a>求解相关系数</h3><p>计算出了空间矩阵后，便可以通过下述的公式分别计算相关系数了。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/G90bwR.png" alt="G90bwR.png"></p>
<h2 id="ms-eCCA-ms-eTRCA"><a href="#ms-eCCA-ms-eTRCA" class="headerlink" title="ms-eCCA + ms-eTRCA"></a>ms-eCCA + ms-eTRCA</h2><p>TRCA是最大化inter-trial之间的协方差，而CCA是最大化inter-stimulus之间的协方差，两者结合会产生更好的效果。（想法是没问题…不过下面这个公式的结合方法也算创新？排列组合中的一种吧…）</p>
<p><font color=red>发现一个有意思的事，这里的融合其实相当于把eCCA和eTRCA的结果进行求和？只是省略了eCCA其中一项而已，但是我之前测试了并没有效果啊（CCA+MSI）？？枯了…</font></p>
<p><img src="https://s1.ax1x.com/2020/03/27/G9DsVs.png" alt="G9DsVs.png"></p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><h2 id="减少训练集"><a href="#减少训练集" class="headerlink" title="减少训练集"></a>减少训练集</h2><p>Multi-stimulus 方法可以减少训练trial数。这在eCCA上的效果尤其明显。</p>
<p><img src="https://s1.ax1x.com/2020/03/27/G9yCgf.png" alt="G9yCgf.png"></p>
<h2 id="组合特征提取效果更佳"><a href="#组合特征提取效果更佳" class="headerlink" title="组合特征提取效果更佳"></a>组合特征提取效果更佳</h2><p>ms-eCCA + ms-eTRCA效果最佳</p>
<p><img src="https://s1.ax1x.com/2020/03/27/G9ysVH.png" alt="G9ysVH.png"></p>
<h1 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h1><p>解决small sample size (SSS) problem，即小样本问题，这在论文Linear discriminant analysis<br>for the small sample size problem: an overview  中已有描述，可以借鉴。 </p>
]]></content>
      <categories>
        <category>BCI</category>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>SSVEP</tag>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title>一些论文idea</title>
    <url>/2020/03/26/%E4%B8%80%E4%BA%9B%E8%AE%BA%E6%96%87idea/</url>
    <content><![CDATA[<p>记录一些不成熟的点子，以后有一定知识量了再来解释和实现。</p>
<a id="more"></a>

<ol>
<li><p>采用对抗生成网络来增加数据集，这一点在情绪脑机接口上已经实现了（参考上海交大吕宝粮老师的研究）。</p>
</li>
<li><p>迁移学习已经应用到BCI上了，但是在SSVEP上的应用并不多见？可以在清华的数据集上测试一下，进行受试者之间的自适应。</p>
</li>
<li><p>清华19年研究了疲劳对SSVEP的影响，发现不同程度的疲劳会对SSVEP的相位和幅值产生影响。刚好14年他们有一篇文章，关于相位锁定CCA的研究（ρ-CCA），是否可以根据检测疲劳从而进行相位自适应？查阅过很多论文，主要难点在疲劳和相位之间的量化分析上…</p>
</li>
</ol>
]]></content>
      <categories>
        <category>学习生活</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title>光影</title>
    <url>/2020/03/26/%E5%85%89%E5%BD%B1/</url>
    <content><![CDATA[<p>下午透过窗口缝隙照射在墙上的光。</p>
<p>…</p>
<a id="more"></a>

<p><img src="https://s1.ax1x.com/2020/03/26/GpemjJ.jpg" alt="GpemjJ.jpg"></p>
]]></content>
      <tags>
        <tag>杂记</tag>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title>CV</title>
    <url>/2020/03/26/CV/</url>
    <content><![CDATA[<p><strong>About me</strong></p>
<center>一个研究BCI的水硕</center>

<center>  一个喜欢旅拍的摄影小白  </center>

<center>一个充满希望打满鸡血的海迷</center>

<center>...</center>

<center>总之</center>

<center>天道酬勤，相信未来</center>

<a id="more"></a>

<hr>
<p><strong>Contact info</strong></p>
<p>Github: <a href="https://github.com/hisunjiang" target="_blank" rel="noopener">hisunjiang</a></p>
<p>CSDN: <a href="https://blog.csdn.net/weixin_42765703" target="_blank" rel="noopener">hi强森</a></p>
<p>Email: <a href="mailto:hisunjiang@outlook.com">hisunjiang@outlook.com</a></p>
]]></content>
  </entry>
  <entry>
    <title>记录一些好用的网站</title>
    <url>/2020/03/26/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>记录一下平时遇到的好用的网站，方便第一时间想起。先成为工具人，再学会挖井~</p>
<a id="more"></a>

<h1 id="编程区"><a href="#编程区" class="headerlink" title="编程区"></a>编程区</h1><ol>
<li><p><a href="https://www.runoob.com/" target="_blank" rel="noopener">菜鸟教程</a><br>里面包含很多编程语言的学习资料，平时复习语法时可以看一看。特别推荐里面提供的很多在线工具。</p>
</li>
<li><p><a href="https://www.liaoxuefeng.com/wiki/896043488029600/896067008724000" target="_blank" rel="noopener">廖雪峰官网Git教程</a><br>里面Git教程很详细，还有一些Python、Java的教程。</p>
</li>
<li><p><a href="https://notepad-plus-plus.org/" target="_blank" rel="noopener">Notepad++</a><br>一个非常简洁小巧的代码编辑器，支持多种源码的查看和编辑。</p>
</li>
<li><p><a href="https://typora.io" target="_blank" rel="noopener">Typora</a><br>一个很好用的Markdown编辑器。</p>
</li>
</ol>
<h1 id="学习区"><a href="#学习区" class="headerlink" title="学习区"></a>学习区</h1><ol>
<li><a href="https://www.sci-hub.tw/" target="_blank" rel="noopener">Sci-hub</a><br>大量的英文文献可以下载，包括一些已经收录但是没有刊载的。离校没有VPN时可以试试这个网站，比百度学术或者Google学术下载更方便。</li>
<li><a href="http://gen.lib.rus.ec/" target="_blank" rel="noopener">Library Genesis</a><br>主要是用来查找一些难以寻找到的英文专业著作等，当然这里面还可以下载论文。均是免费下载，不需要注册。</li>
<li><a href="http://www.6453.net/" target="_blank" rel="noopener">龙猫学术导航</a><br>学术相关的论坛（小木虫等）、资料下载途径（包括上面两个网站）等等均列出来了入口。</li>
<li><a href="http://www.pqdtcn.com/" target="_blank" rel="noopener">ProQuest</a><br>国外硕博论文全文数据库，这需要学校购买权限。</li>
<li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html" target="_blank" rel="noopener">台湾大学李宏毅老师机器学习课程</a><br>看吴恩达老师的课还是有点难以下咽，李宏毅老师的中文机器学习课更易上手，关键是老师人还是特别幽默的台湾腔。刚好今年春期课程开启，作业、video和slides都更新了。当然B站上也有人整理出来了新版的课程，不用上油管观看。</li>
<li><a href="https://ww2.mathworks.cn/matlabcentral/?s_tid=gn_mlc" target="_blank" rel="noopener">MathWorks社区</a><br>里面File Exchange 功能太强大了，这里面能找到很多网友提供的优质MATLAB程序，配合其Documentation工具包说明文档学习，编程更快。</li>
<li><a href="https://www.grammarly.com/" target="_blank" rel="noopener">Grammarly</a><br>强大的英文写作工具，自动检查语法错误并纠正。搭配<a href="http://www.phrasebank.manchester.ac.uk/" target="_blank" rel="noopener">phasebank</a>（曼彻斯特大学学术英语写作语料库，包括论文each part的写作技巧）和<a href="https://www.english-corpora.org/coca/" target="_blank" rel="noopener">coca</a>（当代美语语料库，可以查看一些词语或者短语的用法，以及在美国出版物中的使用频率）一起使用，英语写作更加标准。</li>
</ol>
<h1 id="兴趣区"><a href="#兴趣区" class="headerlink" title="兴趣区"></a>兴趣区</h1><ol>
<li><a href="https://www.pexels.com/zh-cn/" target="_blank" rel="noopener">Pexels</a><br>由摄影作者分享的素材照片，视频等。免费下载无水印，不需要注册。没事可以看看，提高一下审美。</li>
<li><a href="https://unsplash.com/" target="_blank" rel="noopener">Unsplash</a><br>高清素材照片免费下载，无需注册。</li>
<li><a href="https://www.doyoudo.com/" target="_blank" rel="noopener">doyoudo</a><br>Pr、Ps、Ae等软件的教程网。学剪辑当然还是关注B站上的一些摄影师更有收获。</li>
<li><a href="https://docsmall.com/" target="_blank" rel="noopener">docsmall</a><br>一个非常简洁清新的图片压缩、GIF压缩、PDF压缩和分割网站，无广告。</li>
</ol>
]]></content>
      <categories>
        <category>学习生活</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
</search>
